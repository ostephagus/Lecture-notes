\documentclass[../Main.tex]{subfiles}

\begin{document}
\section{Game Theory}
\subsection{Mathematical Description of Games}
Consider a \textit{game} with 2 players where eac player can choose from a number of actions. Let player 1's set of allowed actions be $\{1, 2, \cdots, m\}$ and player 2's set of allowed actions $\{1, 2, \cdots, n\}$.

\begin{definition}{Payoff matrix}
    For each player, that player's \underline{payoff matrix} is a $m \times n$ matrix with entries $A_{ij}$, where $A_{ij}$ is the score attained by player $1$ given that they play action $i$ and player 2 plays action $j$.
\end{definition}
\begin{example}{Rock-paper-scissors}
    Each player (1 and 2) can play one of rock, paper, scissors. Then if rock is assigned $1$, paper is assigned $2$ and scissors is assigned $3$, the payoff matrix for player 1 is:
    \begin{equation*}
        A =
        \begin{pmatrix}
            0 & -1 & 1 \\
            1 & 0 & -1 \\
            -1 & 1 & 0
        \end{pmatrix}
    \end{equation*}
\end{example}
\begin{definition}{Zero-sum game}
    A game is called \underline{zero-sum} if after each round of the game the total payoff is zero.
\end{definition}
Then the \underline{conservative approach} seeks to choose %TODO: WHAT?
For player 1, this is:
\begin{equation*}
    \max_{i \in \{1, \cdots, m\}} \min_{j \in \{1, \cdots, n\}} a_{ij}
\end{equation*}
\begin{example}
    Consider a matrix $A$:
    \begin{equation*}
        A =
        \begin{pmatrix}
            1 & 2 \\
            3 & 4
        \end{pmatrix}
    \end{equation*}
    then in this case, player 1 thinks they should play $i = 1$, and player 2 thinks they should play $j = 1$, so both converge on the cell $A_{21} = 3$.
\end{example}
\begin{example}
    Now consider a payoff matrix:
    \begin{equation*}
        A =
        \begin{pmatrix}
            4 & 2 \\
            1 & 3
        \end{pmatrix} 
    \end{equation*}
    Then in this case the choice of player 1 depends on the choice of player 2, and the choice of player 2 depends on the choice of player 1, so they get stuck in an infinite loop.
\end{example}
\begin{definition}{Strategy}
    A \underline{strategy} is the probability distribution of actions that a player picks.
\end{definition}
\begin{definition}{Pure strategy}
    A \underline{pure strategy} is a strategy where one action has probability 1.
\end{definition}
\begin{definition}{Mixed strategy}
    A \underline{mixed strategy} is a strategy where no one action has probability 1.
\end{definition}
Let player 1 pick action $i$ with probability $p_i$. Let player 2 pick action $j$ with probability $q_j$.

Then player 1 must choose their strategy based on:
\begin{equation*}
    \max_{\vec{p} \in P} \left(\min_{j \in \{1, \cdots, n\}} \sum_{i = 1}^m p_i a_{ij}\right)
\end{equation*}
where $P$ is the set of probability distributions on $\{1, \cdots, m\}$.
\subsection{Linear Programming for Strategies}
We can re-write player 1's problem using the vector $\vec{e}$ which contains $m$ entries all $1$.

\begin{align*}
    \text{Maximise } &v \\
    \text{Subject to } &A^T \vec{p} \geq v\vec{e} \\
    &\vec{e}^T \vec{p} = 1 \\
    \vec{p} \geq 0
\end{align*}
Where here $\vec{p}$ is the vector of probabilities.

We can also re-formulate player 2's problem, using $\vec{e}$ to be $n$-dimensional:
\begin{align*}
    \text{Minimise } &w \\
    \text{Subject to } &A\vec{q} \leq w\vec{e} \\
    &\vec{e}^T \vec{q} = 1 \\
    &\vec{q} \geq 0
\end{align*}
And we can prove that these two problems are duals.

Consider a Lagrangian for player 2's problem:
\begin{equation*}
    L(w, \vec{q}, \vec{s}, \vec{\lambda_1}, \lambda_2) = w + \vec{\lambda_1}^T \left(A\vec{q} + \vec{s} - w\vec{e}\right) - \lambda_2\left(\vec{e}^T\vec{q} - 1\right)
\end{equation*}
Then $\Lambda$ is the set of $\vec{\lambda}$ such that the minimum of the Lagrangian is bounded, and we formulate the dual problem:
\begin{align*}
    \text{Maximise } &\lambda_2 \\
    \text{Subject to } &\vec{\lambda_1}^T \vec{e} = 1 \\
    &\vec{\lambda_1} \geq 0 \\
    &A^T \vec{\lambda_1} \geq \lambda_2\vec{e}
\end{align*}
Then this is also player 1's problem.

\begin{definition}{Nash equilibrium}
    The pair $(\vec{p}, \vec{q})$ that solves the above primal and dual problems is called the \underline{Nash equilibrium}.
\end{definition}

\begin{theorem}
    A strategy $\vec{p}$ is optimal for player 1 if and only if there exists $\vec{q}$ and $v$ such that:
    \begin{enumerate}
        \item The primal is feasible: $A^T\vec{p} \geq v\vec{e}, \vec{e}^T \vec{p} = 1, \vec{p} \geq 0$,
        \item The dual is feasible: $A\vec{q} \leq v\vec{e}, \vec{e}^T\vec{q}, \vec{q} \geq 0$,
        \item Complementary slackness holds: $v = \vec{p}^T A \vec{q}$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    If $(\vec{p}, v)$ and $(\vec{q}, w)$ are optimal, then by complementary slackness:
    \begin{align*}
        (A\vec{q} - w\vec{e})^T \vec{p} &= 0 \\
        (\vec{q}^T A^T\vec{p} - v\vec{e}) = 0
    \end{align*}
    and these are equivalent to $v = w = \vec{p}^T A \vec{q}$.
\end{proof}
\subsection{Finding optimal strategies}
We have some different steps for finding strategies.
\begin{enumerate}
    \item Look for saddle points, in which case a pure strategy is optimal.
    \item Look for \textit{dominating actions}, where each payoff is greater for one action than another no matter the action of the other player. In the payoff matrix, this corresponds to every entry of a row being greater than that of another row. In this case, the action that is dominated can be removed from the space of actions.
    \item After trying the above, formulate and solve the resulting linear program.
\end{enumerate}
\section{Transport Problems}
\subsection{Network Flow Problems}
\begin{definition}{Directed graph}
    A \underline{directed graph} $G = (V, E)$ consists of a set of vertices $V$ and a set of edges $E \subseteq V \times V$.
\end{definition}
Consider a graph with $n$ vertices. Let the vector $\vec{b} \in \R^n$ represent the amount of a good produced or consumed at a vertex. If this quantity is positive, the vertex is a \subsection{source} of the good. If the quantity is negative, the vertex is a \underline{sink}. If we assume that all of the good produced is consumed,
\begin{equation*}
    \sum_{i = 1}^n b_i = 0
\end{equation*}
Consider also an $n \times n$ matrix $C$ such that $C_{ij}$ is the \underline{cost per unit flow} to transport the goods along the edge $(i, j)$.

We also have $n \times n$ matrices $\underbar{M}, \overline{M}$ such that the flow $x_{ij}$ along edge $(i, j)$ is bounded by:
\begin{equation*}
    \underbar{M}_{ij} \leq x_{ij} \leq \overline{M}_{ij}
\end{equation*}
\begin{definition}{Network flow problem}
    The minimum cost flow is a linear program given by:
    \begin{align*}
        \text{Minimise } &\sum_{(i, j) \in E} x_{ij} C_{ij} \\
        \text{Subject to } &b_i + \sum_{j : (j,i) \in E} x_{ji} = \sum_{j : (i, j) \in E} x_{ij} \\
        & \underbar{M}_{ij} \leq x_{ij} \leq \overline{M}_{ij}
    \end{align*}
\end{definition}
\subsection{Defining a Transport Problem}
A transport problem is a special case of of a network flow problem where there are no intermediate vertices.

Consider $n$ suppliers and $m$ consumers. Let supplier $i$ produce $s_i$ goods, and consumer $j$ demand $d_i$ goods. Require that these demands are met:
\begin{equation*}
    \sum_{i = 1}^n s_i = \sum_{j = 1}^m d_j
\end{equation*}
Let the cost per unit flow be $c_{ij}$.

\begin{definition}{Tranport problem}
    The \underline{transport problem} is:
    \begin{align*}
        \text{Minimise } &\sum_{(i, j)} x_{ij} \\
        \text{Subject to } &\sum_{j = 1}^m  x_{ij} = s_i~\forall i \in \{1, \cdots, n\} \\
        &\sum_{i = 1}^n x_{ij} = d_j~\forall j \in \{1, \cdots, m\}
    \end{align*}
\end{definition}
\begin{theorem}{Network flow equivalent to transport problem}
    Every minimum cost network flow problem with finite capacities ($\overline{M}$ is finite) or non-negative costs can be re-cast as an equivalent transport problem
    \label{thmFlowTransportEquiv}
\end{theorem}
\begin{remark}
    By this theorem, any algorithm to solve transport problems solves any network flow problem.
\end{remark}
\begin{proof}
    Given $\vec{b}, C, \underbar{M}, \overline{M}$, observe that $\underbar{M}$ can be set to be $0$ by considering $\tilde{x}_{ij} = x_{ij} - \underbar{M}_{ij}$.

    Now the conditions for $\tilde{x}$ are:
    \begin{align*}
        &0 \leq \tilde{x}_{ij} \leq \overline{M}_{ij} - \underbar{M}_{ij} \\
        &\tilde{b}_i + \sum_{i, j} \tilde{x}_{ij} = \sum_{i, j} \tilde{x}_{ij} \\
        &\text{Where } \tilde{b}_i = \sum_{(i, j) \in E} \underbar{M}_{ij} = \sum_{(i, j) \in E} \overline{M}_{ij} + b_i
    \end{align*}
    Note also that we can can replace any infinite-capacity edge with one with capacity:
    \begin{equation*}
        \overline{M}_{ij} = \sum_i |b_i|
    \end{equation*}
    which can never be exceeded.

    For every $(i, j) \in E$, construct a supplier $(i, j)$, and for every $i \in V$, construct a consumer. Then we have created a bipartite graph with $|E|$ suppliers and $|V|$ consumers. Now, let the supply from supplier $(i, j)$ be $\overline{M}_{ij}$. Let the cost to transport from this supplier to consumer $i$ be 0, and the cost to transport to $j$ be $c_{ij}$. These are the only possible routes for goods from supplier $(i, j)$.
    
    Let the amount of goods consumed by consumer $i$ be:
    \begin{equation*}
        \sum_{k : (i, k) \in E} \overline{M}_{ik} - b_i
    \end{equation*}
    and of consumer $j$ be:
    \begin{equation*}
        \sum_{k : (k, j) \in E} \overline{M}_{jk} - b_j
    \end{equation*}

    Now suppose we send a flow $x_{ij}$ from producer $(i, j)$ to consumer $j$. Then the flow from this producer to consumer $i$ must be $\overline{M}_{ij} - x_{ij}$. The cost of transport is:
    \begin{equation*}
        \sum_{(i, j) \in E} c_{ij} x_{ij}
    \end{equation*}
    Then the constraints on this transport problem are:
    For consumer $i$:
    \begin{equation*}
        \sum_{k : (i, k) \in E} \overline{M}_{ik} - b_i = \sum_{k : (i, k) \in E} (\overline{M}_{ik} - x_{ik}) + \sum_{k : (k, i) \in E} x_{ki}
    \end{equation*}
    and simplifying this:
    \begin{equation*}
        b_i + \sum_{k : (k, i) \in E} x_{ki} = \sum_{k : (i, k) \in E} x_{ik}
    \end{equation*}
    which we note is the same as the original flow problem. Therefore, the problems have the same feasible set. We have already seen that the cost functions are the same, so the problems are equivalent.
\end{proof}
\end{document}