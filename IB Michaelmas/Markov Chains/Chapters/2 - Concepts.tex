\documentclass[../Main.tex]{subfiles}

\begin{document}
\section{Communication Classes}
\begin{definition}{Leads to}
    A state $i$ \underline{leads to} another state $j$ if:
    \begin{equation*}
        \P_i(X_n = j \text{ for some } n\geq 0) > 0
    \end{equation*}
    and we write $i \to j$.
\end{definition}
\begin{definition}{Communication}
    A state $i$ \underline{communicates} with another state $j$ if $i$ and $j$ lead to each other. We write $i \comms j$.
\end{definition}
\begin{theorem}
    The following are equivalent:
    \begin{enumerate}
        \item $i \to j$
        \item There exists a path $x_0 = i, x_1 = x_1, \cdots, x_n = j$ with each step having non-zero transition probability:
            \begin{equation*}
                P_{i, x_1} \Pmat{1}{2} \cdots \Pmat{n-2}{n-1} P_{x_{n-1}, j} > 0
            \end{equation*}
        \item $p_{ij}(n) > 0$ for some $n$.
    \end{enumerate}
    \label{thmCommEquivalence}
\end{theorem}
\begin{proof}
    \begin{subproof}{Statement 1 is equivalent to statement 3}
        \begin{equation*}
            \left\{X_n = j \text{ for some } n \geq 0\right\} = \bigcup_{n \geq 0} \left\{X_n = j\right\}
        \end{equation*}
        so if $\P_i(X_n = j \text{ for some } n \geq 0) > 0$, then there exists some $n \geq 0$ such that $\P_i(X_n = j) > 0$. Clearly if $\P_i(X_n = j) > 0$ then $i \to j$.
    \end{subproof}
    \begin{subproof}{Statement 2 is equivalent to statement 3}
        \begin{align*}
            P_{ij}(n) &= \P_i(X_n = j) \\
            &= \sum_{x_1, \cdots, x_{n-1}} \P_i(X_1 = x_1, \cdots, X_{n-1} = x_{n-1}, X_n = j) \\
            &= \sum_{x_1, \cdots, x_{n-1}} P_{i, x_1} \Pmat{1}{2} \cdots P_{x_{n-1}, j}
        \end{align*}
        so if $p_{ij}(n) > 0$, there must be at least one element of the sum that is non-zero. Also, if an element of the sum is non-zero then $p_{ij}(n) > 0$.
    \end{subproof}
\end{proof}
\begin{corollary}
    Communication is an equivalence relation on the state space $I$.
    \label{corCommEquivalence}
\end{corollary}
\begin{proof}
    We clearly have that $x \comms x$, and $x \comms y \equiv y \comms x$. By statement $2$ in theorem~\ref{thmCommEquivalence}, we can put the paths together and we have that $x \comms y$ and $y \comms z \implies x \comms z$.
\end{proof}
\begin{definition}{Communication classes}
    An equivalence class defined by communication is a \underline{communication class}.
\end{definition}
\begin{definition}{Closed class}
    A communication class $C \subseteq I$ is \underline{closed} if $x \to y$ for some $x \in C, y \in I$ implies that $y \in C$.
\end{definition}
\begin{definition}{Absorbing state}
    A state $x$ is an \underline{absorbing state} if $\{x\}$ is a closed communication class.
\end{definition}
\begin{definition}{Irreducibility}
    A transition matrix $P$ is \underline{irreducible} if $I$ is a communicating class.
\end{definition}
\section{Hitting Time}
\begin{definition}{First hitting time}
    Let $A \subseteq I$. The \underline{first hitting time} for $A$ is:
    \begin{equation*}
        T_A = \inf \subsetselect{n \geq 0}{X_n \in A}
    \end{equation*}
    Note that this is not necessarily finite, since this is infinite if the Markov chain never gets to $A$, because we define $\inf \emptyset = \infty$.
\end{definition}
\begin{definition}{Hitting probability}
    The \underline{hitting probability} is the function:
    \begin{equation*}
        h^A : I \mapsto [0, 1]
    \end{equation*}
    defined by $h_i^A = \P_i(T_A < \infty), i \in I$.
\end{definition}
\begin{definition}{Mean hitting time}
    The \underline{mean hitting time} is a function $k^A : I \mapsto [0, \infty]$ defined by:
    \begin{equation*}
        k_i^A = \E_i[T_A]
    \end{equation*}
    If $T_A$ is infinite then the mean hitting time must be infinite. If, however, $\P(T_a = \infty) = 0$ we get:
    \begin{equation*}
        k_i^A = \sum_{n = 0}^\infty \P_i (T_A = n)
    \end{equation*}
\end{definition}
\begin{theorem}
    If $\chain{X} = (X_n)_{n\geq 0}$ is a Markov chain with transition matrix $P$ on $I$ and $A \subseteq I$, then the hitting probabilities $h_i^A$ satisfy:
    \begin{equation}
        \begin{cases}
            1 & i \in A \\
            \sum_{j \in I} P(i, j) h_j^A & i \notin A
        \end{cases}
        \label{eqnHittingProb}
    \end{equation}
    moreover, $(h_i^A)$ is the minimal solution to equation~\ref{eqnHittingProb}, that is, if $(h_i)$ also solves the equation then $h_i^A \leq h_i$ for all $i$.
    \label{thmHittingProb}
\end{theorem}
\begin{proof}
    If $i \in A$ then $h_i^A = 1$ by definition. Therefore assume that $i \notin A$.

    \begin{align*}
        h_i^a &= \P_i(T_A < \infty) \\
        &= \P_i(X_0 \in A) + \P_i(X_0 \notin A, X_1 \in A) \\
        &+ \cdots + \P_i(X_0 \notin A, X_1 \notin A, \cdots, X_n \in A) \\
        &= \sum_{n \geq 1} \P_i(X_0 \notin A, \cdots, X_{n-1} \notin A, X_n \in A) \\
        &= \sum_{n \geq 1} \sum_{j \in I}\P_i (X_0 \notin A, \cdots, X_{n-1} \notin A, X_n \in A, x_1 = j) \\
        &= \sum_{j \in I} \left(\P_i(X_1 \in A, X_1 = j) \right. \\
        &= \left.\sum_{n \geq 2} \sum_{j \in I}\P_i (X_1 \notin A, \cdots, X_{n-1} \notin A, X_n \in A, x_1 = j)\right) \\
        &= \left(P_i(X_1 \in A | X_1 = j) P(i, j)\right. \\
        &+ \left(\sum_{n\geq 2} P_i(X_1 \notin A, \cdots, X_{n-1} \notin A, X_n \in A | X_1 \in j)P(i, j)\right) \\
        &= \left(P(X_1 \in A | X_1 = j) P(i, j)\right. \\
        &+ \left(\sum_{n\geq 2} P(X_1 \notin A, \cdots, X_{n-1} \notin A, X_n \in A | X_1 \in j)\right) \\
        &= \sum_{j \in I} P(i, j) \P(X_0 \notin A | X_0 \in j) \\
        &+ \sum_{j \in I} \sum_{n \geq 1} P(i, j) \P(X_0 \notin A, \cdots, X_{n-1} \notin A, X_{n-1} \in A | X_0 = j) \\
        &= \sum_{j \in I} \sum_{n \geq 0} \P_j(T_A = n) P(i, j) \\
        &= \sum_{j \in I} \P_j(T_A < \infty) P(i, j) \\
        &= \sum_{j \in I} P(i, j) h_j^A \\
    \end{align*}
    as required.

    Now to see that this solution is minimal, let $h_i$ be a different solution.  If $i \in A, h_i^A = h_i = 1$, so indeed $h_i^A$ is at most $h_i$. Consider now $i \notin A$:
    \begin{align*}
        h_i &= \sum_{j \in I} P(i, j) h_j \\
        &= \sum_{j \in A} P(i, j) + \sum_{j \notin A} P(i, j) h_j \\
        &= \sum_{j \in A} P(i, j) + \sum_{j \notin A} \left[\sum_k P(j, k) h_k\right] \\
        &= \sum_{j \in A} P(i, j) + \sum_{j \notin A, k \in A} P(i, j) P(j, k) + \sum_{j \notin A, k \notin A} P(i, j) P(j, k) h_k \\
        &= \sum_{j_1 \in A} P(i, j_1) + \sum_{j_1 \notin A, j_2 \in A} P(i, j_1) P(j_1, j_2) \\
        &+ \cdots + \sum_{j_1, \cdots, j_{n-1} \notin A, j_n \in A} P(j_1, j_2) \cdots P(j_{n-1}, j_n) \\
        &+ \sum_{j_1, \cdots, j_{n}} P(j_1, j_2) \cdots P(j_{n-1}, j_n)h_{j_n} \\
        &= \P_i(T_A = 1) + \P_i(T_A = 2) + \cdots + \P_i(T_A = n) \\
        &+ \sum_{j_1, \cdots, j_{n}} P(j_1, j_2) \cdots P(j_{n-1}, j_n)h_{j_n} \\
        &\geq \P_i(T_A = n) \\
        &\geq \P_i(T_A < \infty) = h_i^A
    \end{align*}
\end{proof}
\begin{example}
    Consider a Markov chain with transition matrix:
    \begin{equation*}
        P=
        \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            \frac12 & 0 & \frac12 & 0 \\
            0 & \frac12 & 0 & \frac12 \\
            0 & 0 & 0 & 0\\
        \end{pmatrix}
    \end{equation*}
    and let $A = \{4\}$.
    We note that states $1$ and $4$ are absorbing states. We want to calculate $h_2^A$.

    By the previous theorem:
    \begin{align*}
        h_1^A&=h_1^A \\
        h_2^A &= \frac12 h_1^A + \frac12 h_2^A \\
        h_3^A &= \frac12 h_2^A + \frac12 h_4^A
    \end{align*}
    but we note that $h_1^A = 0$, so using the above along with minimality, $h_2^A = \frac13$.
\end{example}
\begin{example}
    Consider the random walk on $\N \cup \{0\}$ defined by the transition matrix:
    \begin{align*}
        P(0, 1) &= 1 \\
        P(i, i+1) &= p \\
        P(i, i-1) = q = 1-p
    \end{align*}
    Then we want to know the probability $h_i^A$ if $A = \{0\}$. By the previous theorem:
    \begin{align*}
        h_0^A &= 1 \\
        h_i^A &= ph_{i+1}^A + qh_{i-1}^A 
    \end{align*}
    then this gives a simple difference equation.
    \begin{itemize}
        \item In the case $p \neq q$, we have that $h_i = a + b\left(\frac{q}{p}\right)^i$. \item Therefore, if $q > p$ then we get $b = 0, a = 1$ and so $h_i^A = 1$ for all $i$.
        \item If instead $p > q$ we get $a = 0, b = 1$. We then get that $h_i^A = \frac{q^i}{p^i}$ which is non-zero.
        \item If $p = q$, the general solution has the form $h_i^A = a + bi$. Solving gives $h_i^A = 1$.
    \end{itemize}
\end{example}
\begin{example}
    Consider a population model. $I = \N \cup \{0\}$. Set $P(0, 0) = 1$, and:
    \begin{align*}
        P(i, i+1) &=p_i \in (0, 1) \\
        P(i, i-1) &= q_i = 1- p_i
    \end{align*}
    and the other transitions are probability $0$. We now want to consider the extinction probability, so $A = \{0\}$. We get $h_0^A = 1$ and:
    \begin{equation*}
        h_{i}^A = q_i h_{i-1}^A + p_i h_{i+1}^A
    \end{equation*}
    Rearranging gives:
    \begin{equation*}
        p_i (h_{i+1}^A - h_i^A) = q_i (h_i - h_{i-1})
    \end{equation*}
    Defining instead $u_i = h_{i}^A - h_{i-1}^A$,
    \begin{equation*}
        u_{i+1} = \frac{q_i}{p_i}u_i
    \end{equation*}
    which has solution:
    \begin{equation*}
        u_{i+1} = \left(\prod_{j=1}^{n}\frac{q_j}{p_j}\right)u_1
    \end{equation*}
    and we denote the product $\gamma_i$. By telescoping sum, the sum of the $u_i$ is just the endpoints:
    \begin{align*}
        \sum_{i=1}^{j}u_i &= h_j^A - h_0 \\
        \therefore h_j^A &= h_0^A + \sum_{i=1}^j u_i \\
        &= 1 + \left(\sum_{i=0}^{j-1}\gamma_i\right)(h_1^A - 1)
    \end{align*}
    But then we use $h_j^A \geq 0$:
    \begin{equation*}
        h_1^A \geq 1 - \left(\sum_{i=0}^{j}\gamma_i\right)^{-1}
    \end{equation*}
    and taking $j \to \infty$,
    \begin{equation*}
        h_1^A \geq 1 - \left(\sum_{i=0}^{\infty}\gamma_i\right)^{-1}
    \end{equation*}
    But by minimality take $h_1^A$ equal to this quantity, $h_1^A = 1 - \frac{1}{S}$.

    We have 2 cases. In the case that $S$ is finite, $h_0^A = 1$ and
    \begin{equation*}
        h_i^A = \frac{\sum_{j=i}^{\infty} \gamma_j}{\sum_{j=0}^{\infty}\gamma_j}
    \end{equation*}
    which is a positive probability that the population does not go extinct.

    In the case that $S$ is infinite, however, we have that $h_i^A = 1$ for all $i$ and therefore the population certainly goes extinct.
\end{example}
\section{Mean Hitting Time}
We have previously defined the mean hitting time. We will derive a similar system of equation for the mean hitting time as we have for the regular hitting time.
\begin{theorem}
    If $\chain{X}$ is a Markov chain with state space $I$ and transition matrix $P$, for a subset $A \subseteq I$ the mean hitting times $(k_i^A)$ are the minimal non-negative solution to:
    \begin{equation*}
        k_i^A =
        \begin{cases}
            0 & i \in A \\
            1 + \sum_{j \notin A} P(i, j) k_j^A & i \notin A
        \end{cases}
    \end{equation*}
    \label{thmMeanHittingProb}
\end{theorem}
\begin{proof}
    If $i \in A$ then $k_i^A = 0$ by definition. Therefore assume that $i \notin A$.

    \begin{align*}
        h_i^a &= \E_i(T_A) = \sum_{n = 0}^\infty \P_i(T_A > n)\\
        &= \sum_{n \geq 0} \P_i(X_0 \notin A, \cdots, X_{n-1} \notin A, X_n \notin A) \\
        &= 1 + \sum_{n \geq 1} \P_i(X_1 \notin A, \cdots, X_{n-1} \notin A, X_n \notin A) \\
        &= 1 + \sum_{n \geq 1} \sum_{j \in I}\P_i (X_1 \notin A, \cdots, X_n \notin A, X_1 = j) \\
        &= 1 + \sum_{n \geq 1} \sum_{j \in I}\P(X_1 \notin A, \cdots, X_n \notin A | X_1 = j)P(i, j) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 0} \P(X_1 \notin A, \cdots, X_n \notin A | X_1 = j) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 1} \P_j(X_0 \notin A, \cdots, X_{n-1} \notin A_) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 1} \P_j(T_A > n-1) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 0} \P_j(T_A > n) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 0} \P_j(T_A > n) \\
        &= 1 + \sum_{j \in I} P(i, j) k_j^A \\
        &= 1 + \sum_{j \notin A} P(i, j) k_j^A \\
    \end{align*}
    as required.

    Now to see that this solution is minimal, let $k_i$ be a different solution.  If $i \in A, k_i^A = k_i = 0$, so indeed $k_i^A$ is at most $k_i$. Consider now $i \notin A$:
    \begin{align*}
        k_i &= 1 + \sum_{j_1 \notin A} P(i, j_1) k_{j_1} \\
        &= 1 + \sum_{j_1 \notin A} P(i, j_1) \left[1 + \sum_{j_2 \notin A} P(i, j_2) k_{j_2}\right] \\
        &= 1 + \sum_{j_1 \notin A} P(i, j_1) + \sum_{j_1, j_2 \notin A} P(i, j_2) k_{j_2} \\
        &\vdots \\
        &= 1 + \sum_{j_1 \notin A} P(i, j_1) + \sum_{j_1, j_2 \notin A} P(i, j_2) \\
        &+ \cdots + \sum_{j_1, \cdots, j_n \notin A} P(i, j_1) P(j_1, j_2) \cdots P(j_{n-1}, j_n) \\
        &+ \sum_{j_1, \cdots, j_{n+1} \notin A} P(i, j_1) \cdots P(j_n, j_{n+1}) k_{j_{n+1}} \\
        &\geq 1 + \P_i(T_A > 1) + \P_i(T_A > 2) + \cdots + \P_i(T_A > n) \\
        &\geq \sum_{n \geq 0} \P_i(T_A > n) = k_i^A \text{ by taking } n \to \infty
    \end{align*}
\end{proof}
\section{Stopping Time and the Strong Markov Property}
\begin{definition}{Stopping time}
    A \underline{stopping time} $T$ for a process $\chain{X}$ on a state space $I$ is a random variable taking values $\N \cup \{0, \infty\}$ such that for all $n \geq 0$ the event $\{T = n\}$ only depends on $X_0, \cdots, X_n$
\end{definition}
\begin{example}[Hitting times are stopping times]
    $\{T_A = n\} = \{X_0 \notin A, \cdots, X_{n-1} \notin A, X_n \in A\}$.
    Then this only depends on the previous states.
\end{example}
\begin{example}[Last Exit times are not stopping times]
    Define the \textit{last exit time} as $S_A = \sup\subsetselect{n \geq 0}{X_n = A}$. Then this is not a stopping time because it depends on the times looking forward (all the way to $\infty$).
\end{example}
\begin{theorem}[Strong Markov Property]
    Suppose $\chain{X} = (X_n)_{n \geq 0}$ is a Markov chain on $I$ with transition matrix $P$, and suppose $T$ is a stopping time.

    Let $i \in I$. Then, conditional on $\{T < \infty\} \cap \{X_T = i\}$, the process $(X_{T+n})_{n \geq 0}$ is a Markov chain with initial distribution $\delta_i$ and transition matrix $P$ which is independent of $(X_0, \cdots, X_T)$.
    \label{thmStrongMarkov}
\end{theorem}
\begin{proof}
    We need to show that, for any path $w \in \cup_{k \geq 0} I^k$, and for any sequence of states $x_0, x_1, \cdots, x_n \in I$,
    \begin{align*}
        &\P\left((x_0, \cdots, x_T) = w, X_T = x_0, \cdots, X_{T+n} = x_n | T < \infty, X_T = i\right) \\
        &= \P((X_0 ,\cdots, X_T) = w | T < \infty, X_T = i) \\
        &\times \mathbb{I}_{X_0 = i} \Pmat{0}{1} \cdots \Pmat{n-1}{n} 
    \end{align*}
    So take the LHS:
    \begin{equation*}
        \frac{\P((x_0, \cdots, x_T) = w, X_T = x_0, \cdots, X_{T+n} = x_n, T < \infty, X_T = i)}{\P(T < \infty, X_T = i)}
    \end{equation*}
    Consider its numerator:
    \begin{align*}
        &\P((x_0, \cdots, x_T) = w, T < \infty, X_T = i) \\
        &\times \P(X_T = x_0, \cdots, X_{T+n} = x_n | T<\infty, X_T = i) \\
        &= \P((x_0, \cdots, x_T) = w, T < \infty, X_T = i) \\
        &\times \P(X_k = x_0, \cdots, X_{k+n} = x_n | T = k, X_k = i) \\
        &\text{ use theorem~\ref{thmMarkovProperty}:} \\
        &= \P((X_0, \cdots, X_T) = w, T < \infty, X_T = i) \textbf{I}_{X_0 = i} \Pmat{0}{1} \cdots \Pmat{n-1}{n}
    \end{align*}
    Then this is only the numerator, so now divide by the denominator:
    \begin{equation*}
        \P((X_0 ,\cdots, X_T) = w | T < \infty, X_T = i) \times \mathbb{I}_{X_0 = i} \Pmat{0}{1} \cdots \Pmat{n-1}{n} 
    \end{equation*}
\end{proof}
Then the power of this theorem is that we can break a Markov chain down into independent and identically distributed (iid) chunks between when a Markov chain visits a given state.
\section{Recurrence and Transience}
\begin{definition}{Recurrent state}
    A state $i$ is \underline{recurrent} if:
    \begin{equation*}
        \P_i(X_n = i \text{ for infinitely many }n) = 1
    \end{equation*}
    For this, we will write $\P_i(X_n = i \io) = 1$.
\end{definition}
Then the matrix $P$ is \underline{recurrent} if all states are recurrent.
\begin{definition}{Transient state}
    A state $i$ is \underline{transient} if:
    \begin{equation*}
        \P_i(X_n = i \io) = 0
    \end{equation*}
\end{definition}
Then the matrix $P$ is \underline{transient} if all states are transient.
\begin{definition}{Return time}
    The \underline{$k$th return time} to $i$, $T_i^{(k)}$ is defined by:
    \begin{equation*}
        T_i^{(k)} =
        \begin{cases}
            0 & k=0 \\
            \inf\subsetselect{n>T_i^{(k-1)}}{X_n = i} & k > 0
        \end{cases}
    \end{equation*}
\end{definition}
Then the previously defined first return time $T_i = T_i^{(1)}$.
\begin{definition}{Return probability}
    The \underline{return probability} for a state $i$ is $f_i = \P_i(T_i < \infty)$.
\end{definition}
\begin{definition}{Total number of visits}
    The \underline{total number of visits} to $i$ is:
    \begin{equation*}
        v_i = \sum_{t = 0}^\infty \mathbb{I}_{X_t = i}
    \end{equation*}
\end{definition}
\begin{lemma}
    For each $r \in \N$, $v_i$ satisfies:
    \begin{equation*}
        \P_i(v_i > r) = f_i^v,~v_i \sim Geo(1-f_i)
    \end{equation*}
    \label{lemReturnGeometric}
\end{lemma}
\begin{proof}
    \induction{$r = 1$}{
        $\P_i(v_i > 0) = 1 = f_i^{(0)}$ as required.
    }{$r \leq k$}{
        Assume true for all $r \leq k$.
    }{$r = k+1$}{
        \begin{align*}
            \P_i(v_i > k+1) &= \P_i(T_i^{(k+1)} < \infty) \\
            &= \P_i(T_i^{(k+1)} < \infty, T_i^{(k)} < \infty) \\
            &= \P_i(T_i^{(k)} < \infty)\P_i(T_i^{(k + 1)} < \infty  T_i^{(k)} < \infty) \\
        \end{align*}
        then by theorem~\ref{thmStrongMarkov}, 
        \begin{equation*}
            \P_i(v_i > k+1) = f_i^k \P_i(T_i^{1} < \infty) = f_i^{k+1}
        \end{equation*}
    }
\end{proof}
\begin{theorem}
    Given a state $i$, if $f_i = 1$ then $i$ is recurrent and $\sum_{n=0}^{\infty} p_{ii}(n) = \infty$.

    If $f_i < 1$ then $i$ is transient and $\sum_{n=1}^{\infty} p_{ii}(n) < \infty$.
    \label{thmReccurOrTrans}
\end{theorem}
\begin{proof}
    First note that:
    \begin{align*}
        \E_i(v_i) &= \E_i \left(\sum_{n=0}^{\infty} \mathbb{I}_{X_n = i}\right) \\
        &= \sum_{n \geq 0} \P_i(X_n = i) \\
        &= \sum_{n \geq 0} p_{ii}(n)
    \end{align*}
    This gives us that if $f_i = 1$ then by lemma~\ref{lemReturnGeometric}, $v_i = \infty$ with probability 1 and $E_i(v_i) = \infty$, so $\sum_{n\geq 0} p_{ii}(n) = \infty$ and $i$ is recurrent.

    If $f_i < 1$, then by the lemma $E_i(v_i) < \infty$ so $P_i(v_i < \infty) = 1$ so $i$ is transient with $\sum_{n \geq 0} p_{ii}(n) < \infty$.
\end{proof}
\begin{theorem}
    If $x \comms y$ then either they are both recurrent or both transient.
    \label{thmRecurrenceCommunicates}
\end{theorem}
\begin{proof}
    Suppose $x$ is recurrent. Since $x \comms y$ there exist $l, m$ such that $p_{xy}(l) > 0$ and $p_{yx}(m) > 0$. Then:
    \begin{align*}
        \sum_{n \geq 0} p_{yy}(n) &\geq \sum_{n \geq 0} p_{yy}(m + n + l) \\
        &\geq \sum_{n \geq 0}p_{yx}(m) p_{xx}(n) p_{xy}(l) \\
        &= p_{yx}(m) p_{xy}(l)\sum_{n \geq 0} p_{xx}(x) \\ 
        &\text{ and this is infinite.}
    \end{align*}
    Therefore, $y$ must also be recurrent. By applying theorem~\ref{thmReccurOrTrans}, we have the required result.
\end{proof}
\begin{corollary}
    If $S \subseteq I$ is a communicating class then either all $i \in S$ are recurrent or all $i \in S$ are transient.
    \label{corComClassRecur}
\end{corollary}
\begin{theorem}
    If $C \subseteq I$ is a recurrent communicating class, then it is closed.
    \label{thmRecurCommClosed}
\end{theorem}
\begin{proof}
    Suppose $x \to y$ with $x \in C, y \notin C$. Then there exists some $m$ such that $p_{xy}(m) > 0$. Note that once $y$ is visited, $x$ is never visited.
    \begin{align*}
        \P_x(v_x < \infty) &\geq P_x(x_n = y) \\
        &= p_{xy}(m) > 0
    \end{align*}
    This implies that $x$ is transient.\contradiction
\end{proof}
\begin{theorem}
    A finite, closed class is recurrent.
    \label{thmFinClosedRecurr}
\end{theorem}
\begin{proof}
    Suppose $C$ is a finite, closed class and take $x \in C$. Then there must exist some $y \in C$ such that:
    \begin{equation*}
        \P_x(X_n = y \io) > 0
    \end{equation*}
    Since $C$ is a communicating class, there is an $m$ such that $p_{yx}(m) > 0$. Then:
    \begin{align*}
        &P_y(X_n = y \io)\\
        &\geq \P_y(X_n = y \io, n > m, X_n = x) \\
        &= \P_y(X_n = y \io, n > m | X_m = x) \P_y(X_m = x) \\
        &= p_{yx}(m) \P_y(X_n = y \io) > 0
    \end{align*}
    This means $y$ is recurrent. Since recurrence is a class property, $C$ is a recurrent class.
\end{proof}
\begin{theorem}
    If a transition matrix $P$ is irreducible and recurrent then:
    \begin{equation*}
        P_x(T_Y < \infty) = 1~\forall x, y \in I
    \end{equation*}
    \label{thmRecurHittingTime}
\end{theorem}
\begin{proof}
    Let $x, y \in I$. Since $x \comms y$, there is an $m$ such that $p_{yx}(m) > 0$. Then:
    \begin{align*}
        1 &= \P_y(X_n = y \io) \\
        &= \sum_x \P_y(X_n = y \io, X_m = x) \\
        &= \sum_x \P_x(X_n = y \io) p_{yx}(m) \\
        &\leq \sum_x \P_x(T_y < \infty)p_{yx}(m)
    \end{align*}
    Since $p_{yx}(m) > 0$, $\P_x(T_y < \infty) = 1$ because we are taking an average of objects less than or equal to 1.
\end{proof}
\section{Simple Symmetric Random Walk}
\begin{definition}{Simple symmetric random walk}
    The \underline{simple symmetric random walk} (SSRW) $\chain{X}$ on the integer lattice $\Z^d$ is the Markov chain $\chain{X} = (X_n)_{n \in \N}$ with transition probabilities:
    \begin{equation*}
        P(x, x + e_i) = P(x, x - e_i) = \frac{1}{2d}
    \end{equation*}
    where $e_i$ is a standard basis vector in $\Z^d$.
\end{definition}
\begin{remark}
    The simply asymmetric random walk on $\Z$ is the Markov Chain with transition probabilities: $P(i, i+1) = p, P(i, i-1) = 1-p$ where $p \notin\{0, \frac12, 1\}$.
\end{remark}
\begin{theorem}
    The SSRW on $\Z^d$ is recurrent for $d = 1, 2$ and transient for $d = 3$.
    \label{thmSSRWRecurr}
\end{theorem}
\begin{remark}
    This theorem reveals something rather profound, in 1 and 2 dimensions we have that the walk will visit every point infinitely often. In 3 dimensions, we have a notion of ``too much choice'', and the random walk will drift off without returning to each point.
\end{remark}
\begin{proof}[In the case $d = 1$]
    Suppose $X_0 = 0$. Note that $\chain{X}$ is irreducible so it suffices to prove recurrence for a single state.

    \begin{align*}
        \sum_{n \geq 0} p_{00}(n) &= \sum_{n \geq 0} p_{00}(2n) \\
        &= \sum_{n \geq 0} \binom{2n}{n} \left(\frac{1}{2}\right)^{2n}
    \end{align*}
    Recall Stirling's formula,
    \begin{equation*}
        n! \sim n^n \sqrt{2\pi n} e^{-n}  
    \end{equation*}
    \begin{align*}
        \sum_{n \geq 0} p_{00}(n) &= \sum_{n \geq 0} \frac{1}{\sqrt{\pi n}} \\
        &\geq \sum_{n \geq 0} \frac{1}{2\sqrt{\pi n}}
    \end{align*}
    This sum is infinite. Therefore, the state $0$ is recurrent. Since the whole chain is irreducible we must have that $\chain{X}$ is recurrent.
\end{proof}
\begin{remark}
    The same computation shows that the simple asymmetric random walk on $\Z$ is transient. Let and $P(x, x+1) = p$, $P(x, x-1) = q = 1-p$. Ensure $p \neq 0 \neq \frac12$.
    \begin{align*}
        \sum_{n\geq 0}p_{00}(n)&= \sum_{n\geq 0} p_{00}(2n) \\
        &= \sum_{n \geq 0} \binom{2n}{n} p^n q^n \\
        &= \sum_{n \geq 0} \frac{(4pq)^n}{\sqrt{\pi n}} \\
    \end{align*}
    Note that $4pq < 1$, so we have a roughly geometric progression that must converge. That is, the walk is transient.
\end{remark}
\begin{lemma}
    Let $f(x, y)$ be the projection of $x, y$ onto the lines $y = x$ and $y = -x$. That is,
    \begin{equation*}
        f(x, y) = \left(\frac{x + y}{\sqrt{2}}, \frac{x-y}{\sqrt{2}}\right)
    \end{equation*}
    Let $(X_n^+, X_n^-) = f(X_n)$. Then $(X_n^+)$ and $(X_n^-)$ are independent SSRWs.
    \label{lemProjectionRW}
\end{lemma}
\begin{proof}
    If $X_0 = 0$ we can write $X_n = \sum_{i=1}^n \xi_i$ where $(\xi_i)_{i \geq 1}$ are independent and identically distributed random variables with:
    \begin{equation*}
       \xi_i =
       \begin{cases}
        (0, 1) & \text{probability } \frac14 \\
        (0, -1) & \text{probability } \frac14 \\
        (1, 0) & \text{probability } \frac14 \\
        (-1, 0) & \text{probability } \frac14
       \end{cases} 
    \end{equation*}
    Write each $\xi_i = (\xi_i^1, \xi_i^2)$ so that:
    \begin{equation*}
        X_n^+ = \sum_{i=1}^{n} \frac{\xi_i^1 +\xi_i^2}{\sqrt{2}},~X_n^- = \sum_{i=1}^{n} \frac{\xi_i^1 -\xi_i^2}{\sqrt{2}}
    \end{equation*}
    From this it immediately follows that $(X_n^+)$ and $(X_i^+)$ are each a SSRW because they are both sums of independent and identically distributed random variables.

    To show independence, it suffices to show $\xi^1 + \xi^2$ is independent of $\xi^1 - \xi^2$. This is easy to check case-by-case, for example:
    \begin{align*}
        \P(\xi^1 + \xi^2 =& 1, \xi^1 - \xi^2 = -1) \\
        &= \P(\xi^1 = 0, \xi^2 = 1) = \frac12 \\
        &= \P(\xi^1 + \xi^2 = 1) \P(\xi^1 - \xi^2 = -1)
    \end{align*}
    And this is applicable for each of the cases.
\end{proof}
\begin{proof}[For theorem~\ref{thmSSRWRecurr} with $d = 2$]
    By the lemma we know that $p_{00}(n)$ is only non-zero when $n$ is even, and:
    \begin{align*}
        p_{00}(2n) &= \P_0(X_n^+ = 0, X_n^- = 0) \\
        &=\P_0(X_n^+ = 0) \P_0(X_n^- = 0) \\
    \end{align*}
    Using lemma~\ref{lemProjectionRW}. Therefore, we can apply the proof for $d = 1$:
    \begin{align*}
        p_{00}(2n) &\sim \sum_{n \geq 0}\frac{1}{\pi n} \\
        & \geq \sum_{n \geq 0} \frac{1}{2\pi n}
    \end{align*}
    This is infinite, and so $0$ is recurrent. Therefore, $\chain{X}$ is recurrent.
\end{proof}
\begin{proof}[For theorem~\ref{thmSSRWRecurr} with $d = 3$]
    We will show that the sum:
    \begin{equation*}
        \sum_{n \geq 0} p_{00}(n) < \infty.
    \end{equation*}
    This will show that $0$ is transient, and since the chain is irreducible then the whole chain must be transient. Recall that $P_{00}(n) = 0$ if $n$ odd.
    \begin{align*}
        p_{00}(2n) &= \sum_{\substack{i, j, k \geq 0\\i + j + k = n}} \binom{2n}{i~i~j~j~k~k} \left(\frac{1}{6}\right)^{2n} \\
        &= \binom{2n}{n} \sum_{i, j, k} \binom{n}{i~j~k}^2 \left(\frac16\right)^{2n}
    \end{align*}
    Now we consider cases based on $n$ mod $3$.
    \begin{case}{$n = 3m$}
        We can show that:
        \begin{equation*}
            \binom{n}{i~j~k} \leq \binom{3m}{m~m~m}
        \end{equation*}
        Then we can apply this:
        \begin{align*}
            p_{00}(2n) &\leq \binom{2n}{n} \left(\frac12\right)^{2n} \left(\frac13\right)^n \binom{3m}{m~m~m} \sum_{i, j, k} \binom{n}{i~j~k} \left(\frac13\right)^n \\
            &= \binom{2n}{n} \left(\frac12\right)^{2n} \left(\frac13\right)^n \binom{3m}{m~m~m} \\
            &\leq \frac{C}{n^{\frac32}}
        \end{align*}
        Therefore $p_{00}(6m) \leq \frac{c}{n^\frac32}$.
    \end{case}
    \begin{case}{$n \neq 3m$}
        We can bound the other cases by the case $n = 3m$:
        \begin{align*}
            p_{00}(6m) &\geq p_{00}(6m-2) \left(\frac{1}{6}\right)^2 \\
            p_{00}(6m) &\geq p_{00}(6m-4) \left(\frac{1}{6}\right)^4
        \end{align*}
    \end{case}
    Therefore we can sum:
    \begin{equation*}
        \sum_{n \geq 0} p_{00}(n) \leq \sum_{n \geq 0} \frac{c}{n^\frac32}
    \end{equation*}
    which is finite. Therefore, state $0$ is transient along with the rest of the chain.
\end{proof}
\end{document}