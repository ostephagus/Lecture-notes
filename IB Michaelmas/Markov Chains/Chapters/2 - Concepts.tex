\documentclass[../Main.tex]{subfiles}

\begin{document}
\section{Communication Classes}
\begin{definition}{Leads to}
    A state $i$ \underline{leads to} another state $j$ if:
    \begin{equation*}
        \P_i(X_n = j \text{ for some } n\geq 0) > 0
    \end{equation*}
    and we write $i \to j$.
\end{definition}
\begin{definition}{Communication}
    A state $i$ \underline{communicates} with another state $j$ if $i$ and $j$ lead to each other. We write $i \comms j$.
\end{definition}
\begin{theorem}
    The following are equivalent:
    \begin{enumerate}
        \item $i \to j$
        \item There exists a path $x_0 = i, x_1 = x_1, \cdots, x_n = j$ with each step having non-zero transition probability:
            \begin{equation*}
                P_{i, x_1} \Pmat{1}{2} \cdots \Pmat{n-2}{n-1} P_{x_{n-1}, j} > 0
            \end{equation*}
        \item $p_{ij}(n) > 0$ for some $n$.
    \end{enumerate}
    \label{thmCommEquivalence}
\end{theorem}
\begin{proof}
    \begin{subproof}{Statement 1 is equivalent to statement 3}
        \begin{equation*}
            \left\{X_n = j \text{ for some } n \geq 0\right\} = \bigcup_{n \geq 0} \left\{X_n = j\right\}
        \end{equation*}
        so if $\P_i(X_n = j \text{ for some } n \geq 0) > 0$, then there exists some $n \geq 0$ such that $\P_i(X_n = j) > 0$. Clearly if $\P_i(X_n = j) > 0$ then $i \to j$.
    \end{subproof}
    \begin{subproof}{Statement 2 is equivalent to statement 3}
        \begin{align*}
            P_{ij}(n) &= \P_i(X_n = j) \\
            &= \sum_{x_1, \cdots, x_{n-1}} \P_i(X_1 = x_1, \cdots, X_{n-1} = x_{n-1}, X_n = j) \\
            &= \sum_{x_1, \cdots, x_{n-1}} P_{i, x_1} \Pmat{1}{2} \cdots P_{x_{n-1}, j}
        \end{align*}
        so if $p_{ij}(n) > 0$, there must be at least one element of the sum that is non-zero. Also, if an element of the sum is non-zero then $p_{ij}(n) > 0$.
    \end{subproof}
\end{proof}
\begin{corollary}
    Communication is an equivalence relation on the state space $I$.
    \label{corCommEquivalence}
\end{corollary}
\begin{proof}
    We clearly have that $x \comms x$, and $x \comms y \equiv y \comms x$. By statement $2$ in theorem~\ref{thmCommEquivalence}, we can put the paths together and we have that $x \comms y$ and $y \comms z \implies x \comms z$.
\end{proof}
\begin{definition}{Communication classes}
    An equivalence class defined by communication is a \underline{communication class}.
\end{definition}
\begin{definition}{Closed class}
    A communication class $C \subseteq I$ is \underline{closed} if $x \to y$ for some $x \in C, y \in I$ implies that $y \in C$.
\end{definition}
\begin{definition}{Absorbing state}
    A state $x$ is an \underline{absorbing state} if $\{x\}$ is a closed communication class.
\end{definition}
\begin{definition}{Irreducibility}
    A transition matrix $P$ is \underline{irreducible} if $I$ is a communicating class.
\end{definition}
\section{Hitting Time}
\begin{definition}{First hitting time}
    Let $A \subseteq I$. The \underline{first hitting time} for $A$ is:
    \begin{equation*}
        T_A = \inf \subsetselect{n \geq 0}{X_n \in A}
    \end{equation*}
    Note that this is not necessarily finite, since this is infinite if the Markov chain never gets to $A$, because we define $\inf \emptyset = \infty$.
\end{definition}
\begin{definition}{Hitting probability}
    The \underline{hitting probability} is the function:
    \begin{equation*}
        h^A : I \mapsto [0, 1]
    \end{equation*}
    defined by $h_i^A = \P_i(T_A < \infty), i \in I$.
\end{definition}
\begin{definition}{Mean hitting time}
    The \underline{mean hitting time} is a function $k^A : I \mapsto [0, \infty]$ defined by:
    \begin{equation*}
        k_i^A = \E_i[T_A]
    \end{equation*}
    If $T_A$ is infinite then the mean hitting time must be infinite. If, however, $\P(T_a = \infty) = 0$ we get:
    \begin{equation*}
        k_i^A = \sum_{n = 0}^\infty \P_i (T_A = n)
    \end{equation*}
\end{definition}
\begin{theorem}
    If $\chain{X} = (X_n)_{n\geq 0}$ is a Markov chain with transition matrix $P$ on $I$ and $A \subseteq I$, then the hitting probabilities $h_i^A$ satisfy:
    \begin{equation}
        \begin{cases}
            1 & i \in A \\
            \sum_{j \in I} P(i, j) h_j^A & i \notin A
        \end{cases}
        \label{eqnHittingProb}
    \end{equation}
    moreover, $(h_i^A)$ is the minimal solution to equation~\ref{eqnHittingProb}, that is, if $(h_i)$ also solves the equation then $h_i^A \leq h_i$ for all $i$.
    \label{thmHittingProb}
\end{theorem}
\begin{proof}
    If $i \in A$ then $h_i^A = 1$ by definition. Therefore assume that $i \notin A$.

    \begin{align*}
        h_i^a &= \P_i(T_A < \infty) \\
        &= \P_i(X_0 \in A) + \P_i(X_0 \notin A, X_1 \in A) \\
        &+ \cdots + \P_i(X_0 \notin A, X_1 \notin A, \cdots, X_n \in A) \\
        &= \sum_{n \geq 1} \P_i(X_0 \notin A, \cdots, X_{n-1} \notin A, X_n \in A) \\
        &= \sum_{n \geq 1} \sum_{j \in I}\P_i (X_0 \notin A, \cdots, X_{n-1} \notin A, X_n \in A, x_1 = j) \\
        &= \sum_{j \in I} \left(\P_i(X_1 \in A, X_1 = j) \right. \\
        &= \left.\sum_{n \geq 2} \sum_{j \in I}\P_i (X_1 \notin A, \cdots, X_{n-1} \notin A, X_n \in A, x_1 = j)\right) \\
        &= \left(P_i(X_1 \in A | X_1 = j) P(i, j)\right. \\
        &+ \left(\sum_{n\geq 2} P_i(X_1 \notin A, \cdots, X_{n-1} \notin A, X_n \in A | X_1 \in j)P(i, j)\right) \\
        &= \left(P(X_1 \in A | X_1 = j) P(i, j)\right. \\
        &+ \left(\sum_{n\geq 2} P(X_1 \notin A, \cdots, X_{n-1} \notin A, X_n \in A | X_1 \in j)\right) \\
        &= \sum_{j \in I} P(i, j) \P(X_0 \notin A | X_0 \in j) \\
        &+ \sum_{j \in I} \sum_{n \geq 1} P(i, j) \P(X_0 \notin A, \cdots, X_{n-1} \notin A, X_{n-1} \in A | X_0 = j) \\
        &= \sum_{j \in I} \sum_{n \geq 0} \P_j(T_A = n) P(i, j) \\
        &= \sum_{j \in I} \P_j(T_A < \infty) P(i, j) \\
        &= \sum_{j \in I} P(i, j) h_j^A \\
    \end{align*}
    as required.

    Now to see that this solution is minimal, let $h_i$ be a different solution.  If $i \in A, h_i^A = h_i = 1$, so indeed $h_i^A$ is at most $h_i$. Consider now $i \notin A$:
    \begin{align*}
        h_i &= \sum_{j \in I} P(i, j) h_j \\
        &= \sum_{j \in A} P(i, j) + \sum_{j \notin A} P(i, j) h_j \\
        &= \sum_{j \in A} P(i, j) + \sum_{j \notin A} \left[\sum_k P(j, k) h_k\right] \\
        &= \sum_{j \in A} P(i, j) + \sum_{j \notin A, k \in A} P(i, j) P(j, k) + \sum_{j \notin A, k \notin A} P(i, j) P(j, k) h_k \\
        &= \sum_{j_1 \in A} P(i, j_1) + \sum_{j_1 \notin A, j_2 \in A} P(i, j_1) P(j_1, j_2) \\
        &+ \cdots + \sum_{j_1, \cdots, j_{n-1} \notin A, j_n \in A} P(j_1, j_2) \cdots P(j_{n-1}, j_n) \\
        &+ \sum_{j_1, \cdots, j_{n}} P(j_1, j_2) \cdots P(j_{n-1}, j_n)h_{j_n} \\
        &= \P_i(T_A = 1) + \P_i(T_A = 2) + \cdots + \P_i(T_A = n) \\
        &+ \sum_{j_1, \cdots, j_{n}} P(j_1, j_2) \cdots P(j_{n-1}, j_n)h_{j_n} \\
        &\geq \P_i(T_A = n) \\
        &\geq \P_i(T_A < \infty) = h_i^A
    \end{align*}
\end{proof}
\begin{example}
    Consider a Markov chain with transition matrix:
    \begin{equation*}
        P=
        \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            \frac12 & 0 & \frac12 & 0 \\
            0 & \frac12 & 0 & \frac12 \\
            0 & 0 & 0 & 0\\
        \end{pmatrix}
    \end{equation*}
    and let $A = \{4\}$.
    We note that states $1$ and $4$ are absorbing states. We want to calculate $h_2^A$.

    By the previous theorem:
    \begin{align*}
        h_1^A&=h_1^A \\
        h_2^A &= \frac12 h_1^A + \frac12 h_2^A \\
        h_3^A &= \frac12 h_2^A + \frac12 h_4^A
    \end{align*}
    but we note that $h_1^A = 0$, so using the above along with minimality, $h_2^A = \frac13$.
\end{example}
\begin{example}
    Consider the random walk on $\N \cup \{0\}$ defined by the transition matrix:
    \begin{align*}
        P(0, 1) &= 1 \\
        P(i, i+1) &= p \\
        P(i, i-1) = q = 1-p
    \end{align*}
    Then we want to know the probability $h_i^A$ if $A = \{0\}$. By the previous theorem:
    \begin{align*}
        h_0^A &= 1 \\
        h_i^A &= ph_{i+1}^A + qh_{i-1}^A 
    \end{align*}
    then this gives a simple difference equation.
    \begin{itemize}
        \item In the case $p \neq q$, we have that $h_i = a + b\left(\frac{q}{p}\right)^i$. \item Therefore, if $q > p$ then we get $b = 0, a = 1$ and so $h_i^A = 1$ for all $i$.
        \item If instead $p > q$ we get $a = 0, b = 1$. We then get that $h_i^A = \frac{q^i}{p^i}$ which is non-zero.
        \item If $p = q$, the general solution has the form $h_i^A = a + bi$. Solving gives $h_i^A = 1$.
    \end{itemize}
\end{example}
\begin{example}
    Consider a population model. $I = \N \cup \{0\}$. Set $P(0, 0) = 1$, and:
    \begin{align*}
        P(i, i+1) &=p_i \in (0, 1) \\
        P(i, i-1) &= q_i = 1- p_i
    \end{align*}
    and the other transitions are probability $0$. We now want to consider the extinction probability, so $A = \{0\}$. We get $h_0^A = 1$ and:
    \begin{equation*}
        h_{i}^A = q_i h_{i-1}^A + p_i h_{i+1}^A
    \end{equation*}
    Rearranging gives:
    \begin{equation*}
        p_i (h_{i+1}^A - h_i^A) = q_i (h_i - h_{i-1})
    \end{equation*}
    Defining instead $u_i = h_{i}^A - h_{i-1}^A$,
    \begin{equation*}
        u_{i+1} = \frac{q_i}{p_i}u_i
    \end{equation*}
    which has solution:
    \begin{equation*}
        u_{i+1} = \left(\prod_{j=1}^{n}\frac{q_j}{p_j}\right)u_1
    \end{equation*}
    and we denote the product $\gamma_i$. By telescoping sum, the sum of the $u_i$ is just the endpoints:
    \begin{align*}
        \sum_{i=1}^{j}u_i &= h_j^A - h_0 \\
        \therefore h_j^A &= h_0^A + \sum_{i=1}^j u_i \\
        &= 1 + \left(\sum_{i=0}^{j-1}\gamma_i\right)(h_1^A - 1)
    \end{align*}
    But then we use $h_j^A \geq 0$:
    \begin{equation*}
        h_1^A \geq 1 - \left(\sum_{i=0}^{j}\gamma_i\right)^{-1}
    \end{equation*}
    and taking $j \to \infty$,
    \begin{equation*}
        h_1^A \geq 1 - \left(\sum_{i=0}^{\infty}\gamma_i\right)^{-1}
    \end{equation*}
    But by minimality take $h_1^A$ equal to this quantity, $h_1^A = 1 - \frac{1}{S}$.

    We have 2 cases. In the case that $S$ is finite, $h_0^A = 1$ and
    \begin{equation*}
        h_i^A = \frac{\sum_{j=i}^{\infty} \gamma_j}{\sum_{j=0}^{\infty}\gamma_j}
    \end{equation*}
    which is a positive probability that the population does not go extinct.

    In the case that $S$ is infinite, however, we have that $h_i^A = 1$ for all $i$ and therefore the population certainly goes extinct.
\end{example}
\section{Mean Hitting Time}
We have previously defined the mean hitting time. We will derive a similar system of equation for the mean hitting time as we have for the regular hitting time.
\begin{theorem}
    If $\chain{X}$ is a Markov chain with state space $I$ and transition matrix $P$, for a subset $A \subseteq I$ the mean hitting times $(k_i^A)$ are the minimal non-negative solution to:
    \begin{equation*}
        k_i^A =
        \begin{cases}
            0 & i \in A \\
            1 + \sum_{j \notin A} P(i, j) k_j^A & i \notin A
        \end{cases}
    \end{equation*}
    \label{thmMeanHittingProb}
\end{theorem}
\begin{proof}
    If $i \in A$ then $k_i^A = 0$ by definition. Therefore assume that $i \notin A$.

    \begin{align*}
        h_i^a &= \E_i(T_A) = \sum_{n = 0}^\infty \P_i(T_A > n)\\
        &= \sum_{n \geq 0} \P_i(X_0 \notin A, \cdots, X_{n-1} \notin A, X_n \notin A) \\
        &= 1 + \sum_{n \geq 1} \P_i(X_1 \notin A, \cdots, X_{n-1} \notin A, X_n \notin A) \\
        &= 1 + \sum_{n \geq 1} \sum_{j \in I}\P_i (X_1 \notin A, \cdots, X_n \notin A, X_1 = j) \\
        &= 1 + \sum_{n \geq 1} \sum_{j \in I}\P(X_1 \notin A, \cdots, X_n \notin A | X_1 = j)P(i, j) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 0} \P(X_1 \notin A, \cdots, X_n \notin A | X_1 = j) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 1} \P_j(X_0 \notin A, \cdots, X_{n-1} \notin A_) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 1} \P_j(T_A > n-1) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 0} \P_j(T_A > n) \\
        &= 1 + \sum_{j \in I} P(i, j) \sum_{n \geq 0} \P_j(T_A > n) \\
        &= 1 + \sum_{j \in I} P(i, j) k_j^A \\
        &= 1 + \sum_{j \notin A} P(i, j) k_j^A \\
    \end{align*}
    as required.

    Now to see that this solution is minimal, let $k_i$ be a different solution.  If $i \in A, k_i^A = k_i = 0$, so indeed $k_i^A$ is at most $k_i$. Consider now $i \notin A$:
    \begin{align*}
        k_i &= 1 + \sum_{j_1 \notin A} P(i, j_1) k_{j_1} \\
        &= 1 + \sum_{j_1 \notin A} P(i, j_1) \left[1 + \sum_{j_2 \notin A} P(i, j_2) k_{j_2}\right] \\
        &= 1 + \sum_{j_1 \notin A} P(i, j_1) + \sum_{j_1, j_2 \notin A} P(i, j_2) k_{j_2} \\
        &\vdots \\
        &= 1 + \sum_{j_1 \notin A} P(i, j_1) + \sum_{j_1, j_2 \notin A} P(i, j_2) \\
        &+ \cdots + \sum_{j_1, \cdots, j_n \notin A} P(i, j_1) P(j_1, j_2) \cdots P(j_{n-1}, j_n) \\
        &+ \sum_{j_1, \cdots, j_{n+1} \notin A} P(i, j_1) \cdots P(j_n, j_{n+1}) k_{j_{n+1}} \\
        &\geq 1 + \P_i(T_A > 1) + \P_i(T_A > 2) + \cdots + \P_i(T_A > n) \\
        &\geq \sum_{n \geq 0} \P_i(T_A > n) = k_i^A \text{ by taking } n \to \infty
    \end{align*}
\end{proof}
\section{Stopping Time and the Strong Markov Property}
\begin{definition}{Stopping time}
    A \underline{stopping time} $T$ for a process $\chain{X}$ on a state space $I$ is a random variable taking values $\N \cup \{0, \infty\}$ such that for all $n \geq 0$ the event $\{T = n\}$ only depends on $X_0, \cdots, X_n$
\end{definition}
\begin{example}[Hitting times are stopping times]
    $\{T_A = n\} = \{X_0 \notin A, \cdots, X_{n-1} \notin A, X_n \in A\}$.
    Then this only depends on the previous states.
\end{example}
\begin{example}[Last Exit times are not stopping times]
    Define the \textit{last exit time} as $S_A = \sup\subsetselect{n \geq 0}{X_n = A}$. Then this is not a stopping time because it depends on the times looking forward (all the way to $\infty$).
\end{example}
\begin{theorem}[Strong Markov Property]
    Suppose $\chain{X} = (X_n)_{n \geq 0}$ is a Markov chain on $I$ with transition matrix $P$, and suppose $T$ is a stopping time.

    Let $i \in I$. Then, conditional on $\{T < \infty\} \cap \{X_T = i\}$, the process $(X_{T+n})_{n \geq 0}$ is a Markov chain with initial distribution $\delta_i$ and transition matrix $P$ which is independent of $(X_0, \cdots, X_T)$.
    \label{thmStrongMarkov}
\end{theorem}
\begin{proof}
    We need to show that, for any path $w \in \cup_{k \geq 0} I^k$, and for any sequence of states $x_0, x_1, \cdots, x_n \in I$,
    \begin{align*}
        &\P\left((x_0, \cdots, x_T) = w, X_T = x_0, \cdots, X_{T+n} = x_n | T < \infty, X_T = i\right) \\
        &= \P((X_0 ,\cdots, X_T) = w | T < \infty, X_T = i) \\
        &\times \mathbb{I}_{X_0 = i} \Pmat{0}{1} \cdots \Pmat{n-1}{n} 
    \end{align*}
    So take the LHS:
    \begin{equation*}
        \frac{\P((x_0, \cdots, x_T) = w, X_T = x_0, \cdots, X_{T+n} = x_n, T < \infty, X_T = i)}{\P(T < \infty, X_T = i)}
    \end{equation*}
    Consider its numerator:
    \begin{align*}
        &\P((x_0, \cdots, x_T) = w, T < \infty, X_T = i) \\
        &\times \P(X_T = x_0, \cdots, X_{T+n} = x_n | T<\infty, X_T = i) \\
        &= \P((x_0, \cdots, x_T) = w, T < \infty, X_T = i) \\
        &\times \P(X_k = x_0, \cdots, X_{k+n} = x_n | T = k, X_k = i) \\
        &\text{ use theorem~\ref{thmMarkovProperty}:} \\
        &= \P((X_0, \cdots, X_T) = w, T < \infty, X_T = i) \textbf{I}_{X_0 = i} \Pmat{0}{1} \cdots \Pmat{n-1}{n}
    \end{align*}
    Then this is only the numerator, so now divide by the denominator:
    \begin{equation*}
        \P((X_0 ,\cdots, X_T) = w | T < \infty, X_T = i) \times \mathbb{I}_{X_0 = i} \Pmat{0}{1} \cdots \Pmat{n-1}{n} 
    \end{equation*}
\end{proof}
Then the power of this theorem is that we can break a Markov chain down into independent and identically distributed (iid) chunks between when a Markov chain visits a given state.
\end{document}