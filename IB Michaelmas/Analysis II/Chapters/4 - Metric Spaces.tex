\documentclass[../Main.tex]{subfiles}

\begin{document}
\section{Metrics and Norms}
\begin{definition}{Metric}
    Let $X$ be any set. A \underline{metric} (or distance function) on $X$ is a function $d : X \times X \mapsto \R$ satisfying, for any $x, y, z \in X$, the following axioms:
    \begin{enumerate}
        \item $d(x, y) \geq 0$, with $d(x, y) = 0 \implies x = y$;
        \item $d(x, y) = d(y, x)$;
        \item $d(x, y) \leq d(x, z) + d(y, z)$.
    \end{enumerate}
\end{definition}
\begin{definition}{Metric space}
    For a set $X$ with a metric $d$, the tuple $(X, d)$ is a \underline{metric space}. We will sometimes say $X$ is a metric space if it has a metric $d$.
\end{definition}
\begin{definition}{Norm}
    Let $V$ be a vector space over $\R$. A \underline{norm} on $V$ is a function $||\cdot|| : V \mapsto \R$ satisfying, for any $x, y \in V$ and any scalar $\lambda$,
    \begin{enumerate}
        \item $||x|| \geq 0$ with $||x|| = 0 \implies x = \vec{0}$;
        \item $||\lambda x|| = |\lambda|~||x||$;
        \item $||x + y|| \leq ||x|| + ||y||$.
    \end{enumerate}
\end{definition}
Similarly, a \underline{normed space} is a vector space with associated norm.

Once we have a norm space, this defines a metric on $V$.
\begin{proposition}
    If $(V, ||\cdot||)$ is a normed space, and if $d : V \times V \mapsto \R$ is defined by:
    \begin{equation*}
        d(x, y) = ||x - y||
    \end{equation*}
    then $d$ is a metric, and so $(V, d)$ is a metric space.
    \label{propNormIsMetric}
\end{proposition}
The proof is simply checking the axioms.
\section{Examples}
We will give various examples of normed spaces which, by proposition~\ref{propNormIsMetric}, are also metric spaces.
\subsection{Finite-Dimensional Normed Spaces}
The classic example of a normed space or metric space is $\R^n$.

We can first take $\R^n$ with its usual vector space structure, and define several useful norms for the vector $\vec{x} = (x_1, x_2, \cdots, x_n)^T$:
\begin{enumerate}
    \item Euclidean norm ($\ell_2$ norm):
        \begin{equation*}
            ||x||_2 = \sqrt{\sum_{i=1}^{n} |x_i|^2}
        \end{equation*}
        It is easy to check the first two axioms. For the triangle inequality:
        \begin{align*}
            ||x + y|_2^2 &= \sum_{i=1}^{n} (x_i + y_i)^2 \\
            &= ||x||^2 + ||y||^2 + 2\sum_{i=1}^{n} x_i y_i \\
            &\leq ||x||^2 + ||y||^2 + 2||x||~||y|| \text{ by Cauchy-Schwarz} \\
            &= (||x|| + ||y||)^2
        \end{align*}
    \item The $\ell_1$ norm:
        \begin{equation*}
            ||x||_1 = \sum_{i=1}^{n} |x_i|
        \end{equation*}
    \item The $\ell_\infty$ norm:
        \begin{equation*}
            ||x||_\infty = \sup \subsetselect{|x_i|}{1 \leq i \leq n}
        \end{equation*}
    \item The general $\ell_p$ norm for $p \in \R, p \geq 1$:
        \begin{equation*}
            ||x||_p = \left(\sum_{i=1}^{n} |x_i|^p\right)^\frac1p
        \end{equation*}
\end{enumerate}
\subsection{Normed Spaces of Sequences}
Consider first the set of sequences of real numbers, $\R^\N = \subsetselect{(x_k)_{k \in \N}}{x_k \in \R~\forall k \in \N}$. Then this is a vector space under addition and scalar multiplication, defined termwise. We cannot provide a norm that is finite for the whole space. However, we can define norms and consider the spaces for which those norms are finite.
\begin{enumerate}
    \item Consider the $\ell_1$ space: $\ell_1 = \subsetselect{(x_k) \in \R^\N}{\sum_{k=1}^\infty |x_k| < \infty}$. Then this is a linear subspace of $\R^\N$, and is a normed space under the $\ell_1$ norm.
    \item We can do the same thing with $\ell_2$: define the $\ell_2$ space: $\ell_1 = \subsetselect{(x_k) \in \R^\N}{\sqrt{\sum_{k=1}^\infty |x_k|^2} < \infty}$. Then this is a linear subspace of $\R^\N$, and is a normed space under the $\ell_2$ norm.
    \item We can then make different normed subspaces with the $\ell_p$ norm, including $\ell_\infty$.
\end{enumerate}
\begin{remark}
    The $\ell_p$ norm as defined on $\R^\N$ is the limit of the $\ell_p$ norm on $\R^n$ as $n \to\infty$:
    \begin{equation*}
        ||(x_k)||_p = \lim_{n \to \infty} ||(x_1, x_2, \cdots, x_n)||_p
    \end{equation*}
\end{remark}
\subsection{Normed Spaces of Functions}
Consider a vector space $V = C([a, b])$. Then this is a vector space under pointwise addition and scalar multiplication of functions. We can define:
\begin{enumerate}
    \item The $L^1$ norm:
        \begin{equation*}
            ||f||_1 = \int_{a}^{b} |f(x)| dx
        \end{equation*}
    \item The $L^2$ norm:
        \begin{equation*}
            ||f||_2 = \sqrt{\int_{a}^{b} |f(x)|^2 dx}
        \end{equation*}
    \item The $L^\infty$ norm, or uniform norm:
        \begin{equation*}
            ||f||_{\infty} = \sup_{x \in [a, b]} |f(x)|
        \end{equation*}
\end{enumerate}
We can provide explicitly a metric for this space. Say $d(f, g) = ||f - g||_\infty$. That is,
\begin{equation*}
    d(f, g) = \sup_{x \in [a, b]} |f(x) - g(x)|
\end{equation*}
Note the similarity with uniform convergence.

\begin{remark}
    Integral norms like $L^1$ and $L^2$ seem to permit integrable functions (a wider class than just continuous functions). Indeed the set of integrable functions on $[a, b]$ is a vector space. However, there are integrable functions that are zero on only a countable set of points, which means their integral is zero, and so is their norm. This violates the first condition of a norm. However, we can define an equivalence relation to say that $f \sim g$ if $f = g$ \underline{almost everywhere} (everywhere except a set of measure zero). Then we do get a valid norm.
\end{remark}
\subsection{Metrics on Generic Sets}
For any set $X$, define:
\begin{equation*}
    d(x, y) =
    \begin{cases}
        0 & x = y \\
        1 & \text{otherwise}
    \end{cases}
\end{equation*}
Then this is a valid metric, but it does not tell us much about the distance between elements in the set.

We can also define metrics from other metrics. For example, given a set $X$ with metric $d$, we can define a new metric:
\begin{align*}
    g : X \times X &\mapsto \R\\
    (x, y) &\mapsto \min\{1, d(x, y)\}
\end{align*}
Alternatively,
\begin{align*}
    h : X \times X &\mapsto \R\\
    (x, y) &\mapsto \frac{d(x, y)}{1 + d(x, y)}
\end{align*}
Then $g(x, y) \leq 1$ for all $x, y \in X$ and $h(x, y) < 1$ for all $x, y \in X$.

For a more concrete example, let $X = R^n$. Define:
\begin{align*}
    d : \R^n \times \R^n &\mapsto \R\\
    (x, y) &\mapsto \begin{cases}
        ||x - y||_2 & x = ty \\
        ||x|| + ||y|| & \text{otherwise}
    \end{cases}
\end{align*}
Then this metric defines a distance only radially. If two points are on a radius, then the distance under $d$ is the Euclidean distance. If not, the distance under $d$ is the Euclidean distance from point $x$ to $y$ via the origin. This is called the \underline{French Railways Metric} or \underline{SNCF metric}, as a joke that all travellers must go through Paris (the origin) to get to a destination anywhere not on their own train line.
\section{Metric Subspaces}
\begin{definition}{Subspace metric}
    Let $X$ be a metric space with metric $d$. Let $Y\subseteq X$ be any subset. Then the restriction $d|_{Y \times Y} : Y \times Y \mapsto \R$ is a metric on $Y$ called the \underline{subspace metric} or \underline{induced metric} on $Y$.
\end{definition}
\begin{definition}{Open ball}
    Let $(X, d)$ be a metric space. For any point $a \in X$ and any $r > 0$, the \underline{open ball} with radius $r$ and centre $a$ is the set:
    \begin{equation*}
        B_r(a) = \subsetselect{x \in X}{d(x, a) < r}
    \end{equation*}
\end{definition}
\begin{definition}{Open subset}
    For a metric space $(X, d)$, a subset $U \subseteq X$ is an \underline{open subset} if, for all $a \in U$, there exists a radius $r > 0$ such that $B_r(a) \subseteq U$.
\end{definition}
\begin{remark}
    This definition can be understood as: for any point $a$ in $U$, there exists a radius (however small) around $a$ that does not leave $U$ (or intersect its boundary).
\end{remark}
\begin{definition}{Closed subset}
    For a metric space $(X, d)$, a subset $E \subseteq X$ is a \underline{closed subset} if $X \backslash E$ is open.
\end{definition}
\begin{remark}
    An open subset can also be a closed subset, these are not mutually exclusive definitions.
\end{remark}
\begin{example}[Openness or closedness is relative to the containing space]
    Consider $X = \R$ with the Euclidean metric. Let $Y = [0, 1) \cup \{2\}$ with the induced metric.
    Then $[0, 1)$ is neither open nor closed on $X$, but $[0, 1)$ is both open and closed on $Y$.

    $\{2\}$ is closed on $X$ but not open on $X$, $\{2\}$ is both open and closed on $Y$.
\end{example}
\begin{propositions}{
        Let $(X, d)$ be a metric space
        \label{propsOpenSets}
    }
    \item Any open ball $B_r(a)$ is an open set.
    \item Any singleton $\{x\} \subset X$ is closed.
\end{propositions}
\begin{remark}
    Open balls can be closed sets, and singletons can be open sets.
\end{remark}
\begin{proof}
    \begin{subproof}{Open balls are open sets}
        In order to prove that the open ball is an open set, we take any $y \in B_r(a)$. We need to show that there exists an open ball around $y$ that is contained within our original set. Therefore take $r_1 = r - d(y, a)$. This is a positive quantity since $y \in B_r(a)$. Then take any point $z \in B_{r_1}(y)$.
        \begin{align*}
            d(z, a) &\leq d(z, y) + d(y, a) \\
            &< r_1 + d(y, a) \\
            &= r
        \end{align*}
    \end{subproof}
    \begin{subproof}{Singletons are closed sets}
        Consider the singleton $\{x\}$. Now take $y \in X \backslash \{x\}$, that is, $y \neq x$. Define $r = d(z, x) > 0$. Therefore $x \notin B_r(z)$ for any $z$. 
    \end{subproof}
\end{proof}
\begin{theorem}
    Let $X$ be a metric space with distance function $d$.

    \begin{enumerate}
        \item The union of any (possibly uncountable) collection of open sets is an open set.
        \item The intersection of any finite collection of open sets is open
        \item The empty set $\emptyset$ and $X$ are both open.
    \end{enumerate}
    \label{thmOpennessUnionIntersec}
\end{theorem}
\begin{proof}
    The proof is again using the definitions. % TODO: Come back to when reviewing.
\end{proof}
\begin{remark}
    The finite condition is necessary for part 2. Consider $X = \R$ and the Euclidean metric. Consider the open sets $(-\frac{1}{n}, \frac{1}{n})$. Taking the union over the infinite set $\N$ gives us the singleton $\{0\}$ which is not open.
\end{remark}
\begin{corollary}
    Let $X$ be a metric space with distance function $d$.
    \begin{enumerate}
        \item The intersection of any (possible uncountable) collection of closed sets is closed
        \item The union of any finite collection of closed sets is closed
        \item $\emptyset, X$ are both closed.
    \end{enumerate}
    \label{corClosureUnionIntersec}
\end{corollary}
\begin{proof}
    The proof is immediate from theorem~\ref{thmOpennessUnionIntersec} by taking set complements.
\end{proof}
\section{Convergence in Metric Spaces}
With a notion of distance, we can define convergence of sequences using the distance function:
\begin{definition}{Convergence to a point}
    Let $(X, d)$ be a metric space. A sequence $(x_k)$ in $X$ \underline{converges to a point} $x \in X$ if $d(x_k, x) \to 0$ (as real numbers). That is, given any $\epsilon > 0$ there exists $N \in \N$ such that:
    \begin{align*}
        n \geq N &\implies d(x_n, x) < \epsilon \\
        &\implies x_n \in B_\epsilon(x)
    \end{align*}
\end{definition}
\begin{remark}
    Immediately from the definition, if $x_n$ converges to $x$ then any subsequence $x_{n_j}$ converges to $x$.
\end{remark}
\begin{proposition}
    If, in a metric space $(X, k)$, $x_n \to x$ and $x_n \to y$ then $x = y$
    \label{propUniqueConvergeLimit}
\end{proposition}
\begin{proof}
    Consider the distance from $x$ to $y$:
    \begin{align*}
        d(x, y) &\leq d(x, x_k) + d(y, x_k) \\
        &= 0 \text{ as }n \to \infty
    \end{align*}
    and we conclude that $x = y$.
\end{proof}
\begin{example}[Convergence depends on the metric]
    Consider $X = \R$ and consider both the Euclidean metric and the metric $d(x, y) = |f(x) - f(y)|$ defined by:
    \begin{align*}
        f : \R &\mapsto \R\\
        x &\mapsto \begin{cases}
            0 & x = 1 \\
            1 & x = 0 \\
            x & \text{otherwise}
        \end{cases}
    \end{align*}
    Then we have that the sequence $x_n = \frac{1}{n}$ converges to $0$ in the Euclidean metric, and $1$ in the new metric.
\end{example}
\begin{remark}
    It is therefore possible for the same sequence in a set $X$ to have different limits under different metrics. This can also happen in a normed space, as seen on the second Example Sheet. However, this cannot happen if the normed space is finite-dimensional because, as we shall see later, any two norms on a finite-dimensional space are equivalent.
\end{remark}
\begin{proposition}[Convergence in $\R^n$ with $\ell_2$ norm]
    Convergence in $\R^n$ with respect to the Euclidean norm is equivalent to convergence of the coordinates as real numbers. That is, if $x^{(k)} = (x^{(k)}_1, \cdots, x_n^{(k)})$,
    \begin{equation*}
        x^{(k)} \to x \iff x_j^{(k)} \xrightarrow{k \to \infty} x_j
    \end{equation*}
    \label{propConvergenceRn}
\end{proposition}
\begin{proof}
    Fix $\epsilon > 0$.
    \begin{proofdirection}{$\Rightarrow$}{Suppose that the vectors $x^{(k)}$ converge.}
        We have that there exists $N(\epsilon)$ such that $k \geq n \implies ||x^{(k)} - x||_2 < \epsilon$. Equivalently,
        \begin{equation*}
            \sum_{j=1}^{\infty} (x_j^{(k)} - x_j)^2 < \epsilon^2
        \end{equation*}
        Therefore the terms are individually less than $\epsilon$:
        \begin{align*}
            (x_j^{(k)} - x_j)^2 &< \epsilon \\
            \implies x_j^{(k)} - x_j &< \epsilon
        \end{align*}
        This is for all $j$ when $k \geq N$.
    \end{proofdirection}
    \begin{proofdirection}{$\Leftarrow$}{Suppose that the coordinates $x_j^{(k)}$ converge}
        We have that, for each $j$, there exists $N_j$ such that for all $k \geq N_1, |x_j^{(k)} - x_j| < \frac{\epsilon}{\sqrt{N_j}}$. Then take $N = \max_j \{N_j\}$, squaring and summing gives:
        \begin{equation*}
            \sum_{j=1}^{N} |x_j^{(k)} - x_j|^2 < \epsilon^2
        \end{equation*}
        Therefore, we get the required result $||x^{(k)} - x|| < \epsilon$.
    \end{proofdirection}
\end{proof}
\begin{remarks}
    \item Here we did not have to use the Euclidean metric. Any metric would have worked for $\R^n$.
    \item We can see very clearly where the problem would arise in the infinite-dimensional case. Here we would not be able to control the size of the sum of infinitely many coordinates.
    \item As an infinite-dimensional example, convergence in $(C([a, b]), ||\cdot||_{\infty})$ is uniform convergence that we have studied extensively.
\end{remarks}
\begin{definition}{Bounded set}
    Consider a metric space $(X, d)$. A subset $E$ is a \underline{bounded set} if $E \subseteq B_R(a)$ for some $a \in X$ and some finite $R > 0$.
\end{definition}
\begin{theorem}[Bolzano-Weierstrass Theorem in $\R^n$]
    Every bounded sequence in $\R^n$ with respect to the Euclidean metric has a convergent subsequence.
    \label{thmBWInRN}
\end{theorem}
\begin{proof}
    \induction{$n = 1$}{
        We have proved the case $n = 1$ in Analysis I - this is the Bolzano Weierstrass Theorem in $\R$
    }{$n = m - 1$}{
        Suppose that the theorem holds in $\R^{m-1}$.
    }{$n = m$}{
        Let $(X^{(k)})$ be a bounded sequence in $\R^m$, say $||x^{(k)}||_2^2 \leq R^2$ for some $R$ and all $k$. Write this as:
        \begin{align*}
            x^{(k)} &= (x_1^{(k)}, \cdots, x_{m-1}^{(k)}, x_m^{(k)}) \\
            y^{(k)} &= (x_1^{(k)}, \cdots, x_{m-1}^{(k)})
        \end{align*}
        Then $||y^{(k)}||_2^2 + |x_m^{(k)}|^2 \leq R^2$. That is, both sequences are bounded. Now by the base case $x_m^{(k)}$ has a convergent subsequence, and by the induction hypothesis so must $y^{(k)}$. Let the convergent subsequences be:
        \begin{align*}
            y^{(k_j)} &\xrightarrow{j \to \infty} y \in \R^{n-1} \\
            x_m^{(k_j)} &\xrightarrow{j \to \infty} x_m \in \R
        \end{align*}
        Now we can use proposition~\ref{propConvergenceRn} once in the forward direction to get that the coordinates of $y^{(k)}$ converge, and once in the backward direction to get that these coordinates, along with $x_m^{(k)}$ converge to form a convergent subsequence in $\R^m$.
    }
\end{proof}
\begin{example}[B-W does not hold in the space of sequences]
    Consider the space $\ell_{\infty}$ of bounded sequences. Consider a sequence $e^{(k)}$ (note that these are themselves sequences) which are defined by $e^{(k)}_n = \delta_{kn}$. That is, they are all zero except have $1$ at the $k$th index. These all have norm $1$, so despite being bounded we find that there can be no convergence in norm.
\end{example}
\begin{remark}
    In fact the converse holds: for any normed space, if the Bolzano-Weierstrass theorem holds then the space must be finite-dimensional. This is an exercise on the example sheet.
\end{remark}
\begin{definition}{Limit point}
    Consider a metric space $(X, d)$ and a subset $E \subseteq X$. Then any $x \in E$ is a \underline{limit point} of $E$ if there exists a sequence $(x_k) \in E$ with $x_k \neq x$ for every $k$ and $x_k \to x$.
\end{definition}
\begin{definition}{Isolated point}
    With $E$ a subset of a metric space $X$, a point $x \in E$ is an \underline{isolated point} if $x$ is not a limit point of $E$.
\end{definition}
\begin{definition}{Closure}
    For a metric space $X$ with subset $E$, the \underline{closure} of $E$, $\bar{E}$, is the set of all limits of sequences of $E$.
\end{definition}
\begin{remark}
    The closure of $E$ is the union of $E$ with its limit points.
\end{remark}
\begin{definition}{Interior point}
    Let $X$ be a metric space with $E \subseteq X$. A point $x \in X$ is an \underline{interior point} of $E$ if there exists a radius $r > 0$ such that $B_r(x) \subseteq E$.
\end{definition}
\begin{definition}{Interior}
    For $X$ a metric space and $E$ a subset, the \underline{interior} of $E$, denoted $\interior{E}$ is the set of interior points of $E$.
\end{definition}
\begin{remark}
    It follows immediately that $x \in E$. We also find that in an open set, every point is an interior point, $E = \interior{E}$.
\end{remark}
\begin{example}
    Take $X = \R$ with the Euclidean metric. Consider $E = [0, 1) \cup \{2\}$. Then the set of limit points is $\{1\}$, and the closure of $E$ is $\bar{E} = [0, 1] \cup \{2\}$. The interior is $\interior{E} = (0, 1)$.
\end{example}
\begin{proposition}
    For any $E \subseteq X$, $\bar{E}$ is a closed set, and is the smallest closed set that contains $E$:
    \label{propClosureIsClosed}
\end{proposition}
\begin{proof}
    The proof is on the second example sheet.
\end{proof}
\begin{proposition}
    Let $X \subseteq X$. Then the following are equivalent:
    \begin{enumerate}
        \item If $(x_k)$ is a sequence in $E$ with $x_n \to x \in X$ then $x \in E$
        \item $E = \bar{E}$
        \item $E$ is a closed set in $X$
    \end{enumerate}
    \label{propSubsetClosure}
\end{proposition}
\begin{proof}
    This directly follows from the definitions and proposition~\ref{propClosureIsClosed}
\end{proof}
\section{Completeness}
\begin{definition}{Cauchy sequence}
    Let $(X, d)$ be a metric space. Let $(x_n)_n$ be a sequence. This is a \underline{Cauchy sequence} if, given $\epsilon > 0$, there exists an $N$ such that:
    \begin{equation*}
        m, n \geq N \implies d(x_m, x_n) < \epsilon
    \end{equation*}
\end{definition}
\begin{remark}
    Some ideas immediately generalise from the ideas used with $\R$. For example:
    \begin{itemize}
        \item All convergent sequences are Cauchy;
        \item All Cauchy sequences are bounded;
        \item If $x_k$ is Cauchy and has a convergent subsequence converging to a point $x$ then the whole sequence converges to $x$.
    \end{itemize}
\end{remark}
\begin{definition}{Completeness}
    Let $(X, d)$ be a metric space. This is \underline{complete} if every Cauchy sequence in $X$ converges to some element $x \in X$.
\end{definition}
\begin{theorem}[$\R^n$ is complete]
    $\R^n$ with the Euclidean metric is a complete space.
    \label{thmRnComplete}
\end{theorem}
\begin{proof}
    If $(x^{(k)})$ is a Cauchy sequence in $\R^n$, then we find that the coordinates must also be Cauchy sequences. Since $\R$ is complete, these individual coordinate sequences must converge. 
    By proposition~\ref{propConvergenceRn}, the whole sequence must converge.
\end{proof}
\begin{remark}
    We will, in due course, find that any finite-dimensional normed space is complete.
\end{remark}
\begin{theorem}[The space of continuous functions is complete]
    $C([a, b])$ is a complete space with respect to the supremum norm.
    \label{thmCtsComplete}
\end{theorem}
\begin{proof}
    We invoke theorem~\ref{thmCauchyCriterion} to show that uniformly Cauchy functions are uniformly convergent. Further, theorem~\ref{thmUCContinuity} tells us that this limit indeed resides in $C([a, b])$.
\end{proof}
\begin{theorem}[Sequence spaces are complete]
    The spaces $\ell_1, \ell_2, \ell_{\infty}$ are complete.
    \label{thmSequencesComplete}
\end{theorem}
\begin{proof}
    The proof for $\ell_1$ is on the example sheet, and the proof for $\ell_2$ is similar. Consider only $\ell_{\infty}$, the set of bounded sequences. We can understand such sequences as bounded functions $f : \N \mapsto \R$. To prove completeness, take a Cauchy sequence in this space (which is a Cauchy sequence of functions).
    
    We can again invoke theorem~\ref{thmCauchyCriterion} to show that such a function (and so the underlying sequence) converges. We have shown that it is bounded (and so the sequence is in $\ell_{\infty}$) on the first example sheet.
\end{proof}
\end{document}