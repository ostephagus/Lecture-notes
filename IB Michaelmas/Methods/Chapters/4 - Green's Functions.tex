\documentclass[../Main.tex]{subfiles}

\begin{document}
\section{The Dirac Delta Function}
The Dirac Delta function was introduced in IA Differential Equations with the following properties:
\begin{align*}
    \delta(x) &= 0 \text{ if }x \neq 0 \\
    \forall \epsilon > 0, &\int_{-\epsilon}^{\epsilon} \delta(x) dx = 1
\end{align*}
No such function exists.

However, we can attempt to understand this by considering the Dirac Delta Function as the limit of a sequence of functions:
\begin{equation*}
    \delta_n(x) =
    \begin{cases}
        \frac{n}{\alpha}\exp\left[-\frac{1}{1-n^2x^2}\right] & |x| < \frac1n \\
        0 & |x| \geq \frac1n
    \end{cases}
\end{equation*}
where:
\begin{equation*}
    \int_{-1}^{1} \exp\left[-\frac{1}{1-y^2}\right] dy 
\end{equation*}
We note that:
\begin{enumerate}
    \item The function $\delta_n$ is smooth for each $n$;
    \item $\delta_n(x)$ is zero on $|x| \geq \frac1n$;
    \item For all $\epsilon > 0,~\exists N > 0$ such that:
        \begin{equation*}
            n \geq N \implies \int_{-\epsilon}^{\epsilon} \delta_x dx = 1
        \end{equation*}
\end{enumerate}
For the third remark, we simply take $N > \frac1\epsilon$. This results in:
\begin{align*}
    \int_{-\epsilon}^{\epsilon} \delta_n(x) dx &= \int_{-\frac1n}^{\frac1n} \delta_n(x) dx \\
    &= \frac1\alpha \int_{-1}^{1} \exp\left[-\frac{1}{1-y^2}\right] dy \text{ by taking }y = nx \\
    &= 1
\end{align*}
Now consider figure~\ref{figDiracDeltaGraph}. We see that $\lim_{n \to \infty} \delta_n(x) = 0$ if $x \neq 0$ and, for $\epsilon > 0$, we have the required integral property.

Therefore, this \underline{almost} gives us the limit:
\begin{equation*}
    \delta(x) = \lim_{n \to \infty} \delta_n(x)
\end{equation*}
However, the pointwise limit does not exist everywhere:
\begin{equation*}
    \lim_{n \to \infty} \delta_n(0) = \lim_{n \to \infty} \frac{n}{e\alpha}
\end{equation*}
which is infinite.

For this course, we will say that the limit does exist, but in a ``weaker sense'' (see III Distribution Theory \& Applications).

The Dirac Delta function rarely appears in isolation. For example, the key ``picking out'' property:
\begin{equation*}
    \int_{-\infty}^{\infty} f(x)\delta(x - a) dx = f(a)
\end{equation*}
It also has important applications in modelling an impulse:
\begin{equation*}
    \ddot{y} + \omega^2 y = \delta(t)
\end{equation*}
To deal with this, we solve $\ddot{y}_n + \omega^2 y_n = \delta_n(t)$. Then we define $y(t)$ as the pointwise limit $\lim_{n \to \infty} t_n(t)$.

Using this limiting procedure, we can also consider $\delta'(x)$:
\begin{align*}
    \int_{-\infty}^{\infty} \delta'(x)f(x) dx &= \lim_{n \to \infty} \int_{-\infty}^{\infty} \delta_n'(x) f(x) dx \\
    &= -\lim_{n \to \infty} \int_{-\infty}^{\infty} \delta_n(x) f'(x) dx \\
    &= -\int_{-\infty}^{\infty} \delta(x) f'(x) dx = -f'(0)    
\end{align*}
It gets irritating writing all these limits, so we usually deal with the Dirac Delta function itself (where we understand that, behind the scenes, a limiting process is occurring).
\subsection{Periodic delta functions}
Let $\delta^L(x)$ denote the $L$-periodic delta function outside the interval $\left[\left.-\frac{L}{2}, \frac{L}{2}\right)\right.$
We can even take the Fourier series:
\begin{equation*}
    \frac{1}{L} \int_{-\frac{L}{2}}^{\frac{L}{2}} \delta(x) e^{-\frac{2\pi}{L}inx} dx
\end{equation*}
This gives:
\begin{equation*}
    \delta^L(x) \sim \frac{1}{L}\sum_{n \in \Z} e^{\frac{2\pi}{L}inx}
\end{equation*}
Plausibility test:
\begin{align*}
    f(0) &= \int_{-\frac{L}{2}}^{\frac{L}{2}} \delta^L(x) f(x) dx \\
    &= \sum_{n \in Z} \left[\frac{1}{L} \int_{-\frac{L}{2}}^{\frac{L}{2}} e^{\frac{2\pi}{L}inx}f(x) dx \right] \\
    &= \sum_{n \in \Z} \hat{f}_{-n} = \sum_{n \in \Z} \hat{f}_{n} \\
    &= f(0)
\end{align*}
This, although we have dealt with non-convergent sums to find it, is our expected result. Note that, since $\delta_n(x)$ is smooth its Fourier coefficients must decay rapidly, so this is slightly less bad than it looks.
\subsection{Eigenfunction Expansion of \texorpdfstring{$\delta(x)$}{the Delta Function}}
Let $L$ be a Sturm-Liouville operator on the vector space $V \subseteq C^2[a, b]$, where we require that $y \in V$ satisfy real, homogeneous boundary conditions at each non-singular endpoint.

Let $\{Y_k\}_{k=1}^\infty$ be a set of normalised eigenfunctions. Fix $\xi \in [a, b]$, and consider functions $\delta_n(x - \xi)$. For $n$ sufficiently large, $\delta_n(x - \xi) \in V$. By completeness,
\begin{align*}
    \delta(x - \xi) &= \sum_{k=1}^{\infty} \inn{\delta_n(t-\xi)}{Y_k(t)}_W Y_k(x) \\
    &= \sum_{k=1}^{\infty} \left[\int_{a}^{b} \delta_n(t - \xi) Y_k(t) w(t) dt \right] Y_k(x)
\end{align*}
Formally, letting $n \to \infty$,
\begin{equation*}
    \delta(x - \xi) = \sum_{k=1}^{\infty} w(\xi) Y_k(\xi) Y_k(x)
\end{equation*}
We can consider another plausibility test:
\begin{align*}
    f(x) &= \int_{a}^{b} \delta(x - \xi)f(\xi) d\xi \\
    &= \sum_{k=1}^{\infty} \int_{a}^{b} f(\xi) Y_k(\xi) w(\xi) d\xi Y_k(x) \\
    &= \sum_{k=1}^{\infty} \hat{f}_k Y_k(x) \sim f(x)
\end{align*}
\section{Green's Functions}
We want to solve inhomogeneous problems of the form:
\begin{equation}
    \begin{cases}
        Ly = f(x) & x \in (a, b) \\
        y(x) = 0 & x \in \{a, b\}
    \end{cases}
    \label{eqnInhomogProblem}
\end{equation}
Here, $L$ has the form $\alpha(x) \frac{d^{2}}{dx^{2}} + \beta(x) \frac{d}{dx} + \gamma(x)$ where $\alpha(x) \neq 0$.

Now fix $\xi \in (a, b)$. Suppose we can find a function $G = G(x; \xi)$ satisfying:
\begin{equation*}
    \begin{cases}
        L_x[G(x;\xi)] = \delta(x - \xi) & x \in (a, b) \\
        G(x, \xi) = 0 & x \in \{a, b\}
    \end{cases}
\end{equation*}
Now consider the new function defined by:
\begin{equation*}
    y(x) = \int_{a}^{b} G(x;\xi) f(\xi) d\xi
\end{equation*}
Clearly $y(a) = y(b) = 0$. Then applying $L$:
\begin{align*}
    L_x[y(x)] &= \int_{a}^{b} L_x[G(x;\xi)]f(\xi) d\xi \\
    &= \int_{a}^{b} \delta(x - \xi)f(\xi) d\xi \\
    &= f(x)
\end{align*}
Therefore, $y$ solves equation~\ref{eqnInhomogProblem}. We call $G$ a \underline{Green's Function} for $L$ with Dirichlet boundary conditions.

We want to try to understand $G$. Note that on the intervals $(a, \xi)$ and $(\xi, b)$ it must satisfy:
\begin{equation*}
    L_x[G(x;\xi)] = 0
\end{equation*}
This is a nice, 2nd-order, homogeneous ordinary differential equation so we expect $G(x;\xi)$ to be well-behaved here. However, in the neighbourhood of $\xi$, we have that $\alpha(x) \frac{d^{2}G}{dx^{2}}$ will be badly behaved, and we know that $\delta(x - \xi)$ is very badly behaved.
\begin{equation*}
    \alpha(x) \frac{d}{dx}\left[\frac{dG}{dx}\right] = \delta(x - \xi) + \text{ more regular terms}
\end{equation*}
So the key question is: what sort of functions have derivatives that look like $\delta(x - \xi)$?

Recall the sequence $\delta_n$:
\begin{equation*}
    \lim_{n \to \infty} \delta_n(x) = 0, x \neq 0, \text{ and } \forall \epsilon > 0 \lim_{n \to \infty} \int_{-\epsilon}^{\epsilon} \delta_n(x) dx = 1
\end{equation*}
It is therefore natural to consider the functions:
\begin{equation*}
    H_n(x) = \int_{-\infty}^{x} \delta_n(x) dx
\end{equation*}
if we fix $X > 0$ then for $N$ sufficiently large ($\frac1n < X$):
\begin{align*}
    H_n(X) &= \int_{-\frac1n}^{\frac1n} \delta_n(t) dt 
    &= 1
\end{align*}
Similarly fixing $X < 0$, then for $N$ sufficiently large $H_N(X) = 0$. Taking a limit of $H_n$,
\begin{equation*}
    \lim_{n \to \infty} H_n(x) = H(x) =
    \begin{cases}
        1 & x > 0 \\
        0 & x < 0
    \end{cases}
\end{equation*}
Here $H$ is called the \underline{Heaviside function} which satisfies the key property $H'(x) = \delta(x)$.

Armed with this knowledge, we expect to need $\frac{dG}{dx}$ to behave like $H(x - \xi)$ near $x = \xi$. That is, we need $G$ to have a jump discontinuity in its derivative around $x = \xi$. For the behaviour of $G$ we can integrate $H(x)$:
\begin{equation*}
    \int_{a}^{x} H(t - \xi) dt =
    \begin{cases}
        x - \xi & x \geq \xi \\
        0 & x < \xi
    \end{cases}
\end{equation*}
This is a continuous function!

We conclude that we need $G$ to be continuous at $x = \xi$ (and also the rest of the interval), and that $\frac{dG}{dx}$ should have a jump discontinuity at $x = \xi$. To find the magnitude of the jump, integrate:
\begin{equation*}
    \frac{\delta(x - \xi)}{\alpha(x)} = \frac{d^{2}G}{dx^{2}} + \frac{\beta(x)}{\alpha(x)}\frac{dG}{dx} + \frac{\gamma(x)}{\alpha(x)}G
\end{equation*}
over a small region around $\xi$. The LHS is:
\begin{equation*}
    \int_{\xi - \epsilon}^{\xi + \epsilon} \frac{\delta(x) - \xi}{\alpha(x)} dx = \frac{1}{\alpha(\xi)}
\end{equation*}
The RHS is:
\begin{align*}
    \lim_{\epsilon \to 0} &\left.\frac{dG}{dx} \right|_{x = \xi - \epsilon}^{x = \xi + \epsilon} + \int_{\xi - \epsilon}^{\xi + \epsilon} \left[\frac{\beta(x)}{\alpha(x)}\frac{dG}{dx} + \frac{\gamma(x)}{\alpha(x)}G\right] dx \\
    &= \left[\frac{dG}{dx}\right]_{x = -\epsilon}^{x = \epsilon} = \frac{1}{\alpha(\xi)}
\end{align*}
In summary, $G$ satisfies:
\begin{enumerate}
    \item $G(\xi^+;\xi) = G(\xi^-;\xi)$
    \item $\left[\frac{dG}{dx}\right]_{x = -\epsilon}^{x = \epsilon} = \frac{1}{\alpha(\xi)}$.
\end{enumerate}
\begin{example}
    Let $L = \frac{d^{2}}{dx^{2}} + \omega^2$ on the interval $(0, 1)$.

    We want to solve:
    \begin{equation*}
        \begin{cases}
            \frac{d^{2}G}{dx^{2}} + \omega^2 G = \delta(x - \xi) & x \in (0, 1) \\
            G(x;\xi) & x \in \{0, 1\}
        \end{cases}
    \end{equation*}
    We solve the differential equation on either side of $x = \xi$.
    \begin{equation*}
        G(x;\xi) =
        \begin{cases}
            A(\xi) \sin(\omega x) + B(\xi) \cos(\omega x) & x \in (0, \xi) \\
            C(\xi) \sin(\omega (x-1)) + D(\xi) \cos(\omega (x-1)) & x \in (\xi, 1) \\
        \end{cases}
    \end{equation*}
    Applying the boundary conditions gives $B, D = 0$. This is because we wrote the second bit of $G$ using $x-1$ rather than $x$.

    Use the continuity condition:
    \begin{equation*}
        A(\xi) = C(\xi) \frac{\sin(\omega(\xi-1))}{\sin(\omega\xi)}
    \end{equation*}
    Using the derivative jump equation and substituting for $A$:
    \begin{equation*}
        \frac{C(\xi)\omega}{\sin(\omega\xi)} \left[\cos(\omega(\xi - 1))\sin(\omega\xi) - \cos(\omega\xi)\sin(\omega(\xi - 1))\right] = 1
    \end{equation*}
    We have an addition formula:
    \begin{align*}
        1 &= \frac{C(\xi)\omega}{\sin(\omega\xi)} \left[\sin(\omega \xi - \omega(\xi - 1))\right] \\
        &= \frac{C(\xi) \omega}{\sin(\omega \xi)} \sin(\omega) \\
        C(\xi) &= \frac{\sin(\omega \xi)}{\omega \sin(\omega)} \\
        A(\xi) &= \frac{\sin(\omega(\xi - 1))}{\omega \sin \omega}
    \end{align*}
    Then our Green's function becomes:
    \begin{equation*}
        G(x;\xi) = \frac{1}{\omega \sin(\omega)}
        \begin{cases}
            \sin(\omega x) \sin(\omega(\xi - 1)) & x \in (0, \xi) \\
            \sin(\omega \xi) \sin(\omega(x - 1)) & x \in (\xi, 1)
        \end{cases}
    \end{equation*}
    However, this has the form:
    \begin{equation*}
        \text{const } \times
        \begin{cases}
            y_1(x)y_2(\xi) & x \in (0, \xi) \\
            y_1(\xi)y_2(x) & x \in (\xi, 1)
        \end{cases}
    \end{equation*}
    Note that $y_1, y_2$ are linearly independent solutions to $Ly = 0$ with $y_1(0) = 0$ and $y_2(1) = 0$.

    We have a problem! For some values of $\omega$, our Green's Function is not defined. However, it turns out that these are exactly the eigenvalues of the operator $L$. In fact, this can be used to find the eigenvalues of $L$, and is analogous to setting a determinant to zero.
\end{example}
\end{document}